{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vs_bXqDJWwhs"
      },
      "source": [
        "# Triton Attention Systems: Naive ‚Üí Page ‚Üí Flash\n",
        "\n",
        "üéØ **Weekly Goal**  \n",
        "Implement attention from scratch in Triton, profile performance bottlenecks,  \n",
        "understand KV cache memory layouts (PagedAttention), and build a mini FlashAttention kernel  \n",
        "to develop intuition for **IO-awareness, tiling, SRAM reuse, and kernel fusion**.\n",
        "\n",
        "---\n",
        "\n",
        "# Day 2 ‚Äî Naive Triton Attention\n",
        "\n",
        "## Objective\n",
        "\n",
        "Implement the most straightforward attention pipeline:\n",
        "\n",
        "attn = softmax(QK·µÄ) @ V\n",
        "\n",
        "Each stage must be implemented as an independent Triton kernel.  \n",
        "‚ö†Ô∏è No fusion. No tiling optimization. No IO reduction tricks.\n",
        "\n",
        "---\n",
        "\n",
        "## Tasks\n",
        "\n",
        "- [ ] Implement QK·µÄ kernel\n",
        "- [ ] Implement row-wise softmax kernel\n",
        "- [ ] Implement P @ V kernel\n",
        "- [ ] Add optional mask support (causal / padding)\n",
        "- [ ] Validate correctness vs PyTorch reference\n",
        "- [ ] Measure max / mean absolute error\n",
        "- [ ] Test small and large sequence lengths\n",
        "\n",
        "---\n",
        "\n",
        "## Key Concepts\n",
        "\n",
        "- Attention compute complexity: O(n¬≤d)\n",
        "- Memory traffic complexity: O(n¬≤)\n",
        "- Materializing the attention matrix is expensive\n",
        "- Softmax requires multiple passes:\n",
        "  - max reduction\n",
        "  - exp + sum\n",
        "  - normalization\n",
        "\n",
        "---\n",
        "\n",
        "## Deliverables\n",
        "\n",
        "- triton_naive_attention.py\n",
        "- Correctness validation script\n",
        "- Basic latency benchmark (ms)\n",
        "\n",
        "---\n",
        "\n",
        "# Day 3 ‚Äî Profiling & Bottleneck Analysis\n",
        "\n",
        "## Objective\n",
        "\n",
        "Diagnose why naive attention is slow using Nsight Compute.\n",
        "\n",
        "---\n",
        "\n",
        "## Tasks\n",
        "\n",
        "- [ ] Profile kernels with Nsight Compute\n",
        "- [ ] Collect:\n",
        "  - DRAM throughput\n",
        "  - SM efficiency\n",
        "  - Achieved occupancy\n",
        "  - Warp stall reasons\n",
        "- [ ] Identify whether bottleneck is:\n",
        "  - memory-bound\n",
        "  - reduction-bound\n",
        "  - compute-bound\n",
        "- [ ] Sweep:\n",
        "  - block sizes\n",
        "  - sequence length (512 ‚Üí 4k ‚Üí 8k)\n",
        "  - fp16 vs fp32\n",
        "\n",
        "---\n",
        "\n",
        "## Key Concepts\n",
        "\n",
        "- Softmax is typically memory-bound\n",
        "- QK·µÄ behaves like GEMM (often compute-bound)\n",
        "- Writing and rereading n¬≤ matrices dominates IO\n",
        "- Arithmetic intensity determines roofline behavior\n",
        "\n",
        "---\n",
        "\n",
        "## Deliverables\n",
        "\n",
        "### Performance Table\n",
        "\n",
        "| Impl  | ms | GB/s | TFLOPs | Speedup |\n",
        "|-------|----|------|--------|---------|\n",
        "| Torch |    |      |        | 1.0x    |\n",
        "| Naive |    |      |        |         |\n",
        "\n",
        "### Bottleneck Analysis Writeup\n",
        "\n",
        "Explain:\n",
        "\n",
        "- Why softmax is IO-heavy  \n",
        "- Why n¬≤ memory traffic dominates  \n",
        "- What stall reason dominates  \n",
        "- Whether QK·µÄ saturates compute units  \n",
        "\n",
        "---\n",
        "\n",
        "# Day 4 ‚Äî PageAttention (KV Cache Layout)\n",
        "\n",
        "## Objective\n",
        "\n",
        "Understand how vLLM reduces KV memory waste via block-based paging.\n",
        "\n",
        "---\n",
        "\n",
        "## Tasks\n",
        "\n",
        "- [ ] Study contiguous KV layout\n",
        "- [ ] Study paged KV layout\n",
        "- [ ] Design fixed-size KV blocks\n",
        "- [ ] Implement logical-to-physical block mapping\n",
        "- [ ] Write toy Triton PageAttention kernel\n",
        "- [ ] Validate correctness\n",
        "- [ ] Measure memory usage\n",
        "\n",
        "---\n",
        "\n",
        "## Key Concepts\n",
        "\n",
        "- KV cache grows linearly with sequence length\n",
        "- Contiguous layout leads to fragmentation\n",
        "- Paged layout uses block tables\n",
        "- Improves memory utilization for long-context inference\n",
        "\n",
        "---\n",
        "\n",
        "## Memory Comparison\n",
        "\n",
        "| Mode        | KV Memory | Fragmentation | Best Use Case |\n",
        "|------------|------------|---------------|---------------|\n",
        "| Contiguous |            |               |               |\n",
        "| Paged      |            |               |               |\n",
        "\n",
        "---\n",
        "\n",
        "## Deliverables\n",
        "\n",
        "- triton_page_attention.py\n",
        "- Memory usage comparison\n",
        "- Short explanation of when paging helps\n",
        "\n",
        "---\n",
        "\n",
        "# Day 5 ‚Äî FlashAttention Theory & Tiling Design\n",
        "\n",
        "## Objective\n",
        "\n",
        "Understand IO-aware attention and why FlashAttention is faster.\n",
        "\n",
        "---\n",
        "\n",
        "## Tasks\n",
        "\n",
        "- [ ] Study FlashAttention core ideas:\n",
        "  - SRAM reuse\n",
        "  - Block Q\n",
        "  - Block K\n",
        "  - Online softmax\n",
        "  - Avoid n¬≤ materialization\n",
        "- [ ] Derive why IO is reduced\n",
        "- [ ] Compute arithmetic intensity before vs after tiling\n",
        "- [ ] Design kernel parameters:\n",
        "  - BLOCK_M\n",
        "  - BLOCK_N\n",
        "  - BLOCK_D\n",
        "- [ ] Write kernel skeleton:\n",
        "  - for k_tile in K:\n",
        "  - compute qk_tile\n",
        "  - update running max\n",
        "  - update running sum\n",
        "  - accumulate output\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "## Key Concepts\n",
        "\n",
        "- Avoid writing S (n √ó n) to DRAM\n",
        "- Online softmax enables single-pass normalization\n",
        "- FlashAttention reduces memory traffic from O(n¬≤) ‚Üí O(nd)\n",
        "- Kernel fusion increases arithmetic intensity\n",
        "\n",
        "---\n",
        "\n",
        "## Deliverables\n",
        "\n",
        "- FlashAttention design document\n",
        "- Arithmetic intensity comparison\n",
        "- Kernel skeleton file\n",
        "\n",
        "---\n",
        "\n",
        "# Day 6 ‚Äî Triton FlashAttention (Mini Version)\n",
        "\n",
        "## Objective\n",
        "\n",
        "Implement a fused, tiled attention kernel in Triton.\n",
        "\n",
        "---\n",
        "\n",
        "## Tasks\n",
        "\n",
        "- [ ] Implement tiled QK·µÄ\n",
        "- [ ] Implement online softmax\n",
        "- [ ] Fuse V multiplication\n",
        "- [ ] Integrate into single kernel\n",
        "- [ ] Validate correctness\n",
        "- [ ] Benchmark vs naive implementation\n",
        "\n",
        "---\n",
        "\n",
        "## Final Comparison\n",
        "\n",
        "| Impl   | ms | GB/s | TFLOPs | Speedup |\n",
        "|--------|----|------|--------|---------|\n",
        "| Naive  |    |      |        | 1.0x    |\n",
        "| Flash  |    |      |        | 2.0x+   |\n",
        "\n",
        "---\n",
        "\n",
        "## Key Concepts\n",
        "\n",
        "- SRAM reuse eliminates n¬≤ writes\n",
        "- Fusion reduces global memory traffic\n",
        "- FlashAttention shifts kernel toward compute-bound region\n",
        "- IO-awareness matters more than reducing FLOPs\n",
        "\n",
        "---\n",
        "\n",
        "# End-of-Week Takeaways\n",
        "\n",
        "- Attention performance is dominated by memory traffic\n",
        "- Softmax is more memory-bound than QK·µÄ\n",
        "- Kernel fusion drastically improves arithmetic intensity\n",
        "- FlashAttention works by reducing IO, not reducing math\n",
        "- Triton enables CUDA-level attention kernel design in Python\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fvND3OxsZRtf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1409dd10-c6c4-4b38-9448-69ea5ae807d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[check_correctness] N=128, D=64, dtype=torch.float16, use_mask=True\n",
            "  max_abs_err : 1.192093e-06\n",
            "  mean_abs_err: 6.595712e-08\n",
            "  rmse        : 1.132886e-07\n",
            "\n",
            "[quick_bench]\n",
            "N=1024, D=64, dtype=torch.float16, mask=False\n",
            "Triton: 4.712 ms\n",
            "Torch : 0.145 ms\n",
            "Speedup (Torch/Triton): 0.03x\n"
          ]
        }
      ],
      "source": [
        "# triton_naive_attention_skeleton.py\n",
        "# ============================================================\n",
        "# Day 2 ‚Äî Triton Naive Attention Kernel (NO SOLUTION)\n",
        "# Goal:\n",
        "#   Implement naive attention:\n",
        "#       attn = softmax(Q @ K.T) @ V\n",
        "#   - Separate kernels for each step (QK^T, softmax, PV)\n",
        "#   - Correctness validation vs PyTorch\n",
        "#   - Support mask (causal / padding via additive -inf)\n",
        "#   - Intentionally NOT optimized (no fusion, no FlashAttention tricks)\n",
        "#\n",
        "# Notes:\n",
        "#   - This is a skeleton with TODOs only. Fill in kernels + launcher code.\n",
        "#   - Keep correctness first; performance will be poor by design.\n",
        "# ============================================================\n",
        "\n",
        "import math\n",
        "import torch\n",
        "import triton\n",
        "import triton.language as tl\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Utilities\n",
        "# -----------------------------\n",
        "def _assert_cuda(x: torch.Tensor, name: str):\n",
        "    if not x.is_cuda:\n",
        "        raise ValueError(f\"{name} must be on CUDA, got {x.device}\")\n",
        "    if not x.is_contiguous():\n",
        "        raise ValueError(f\"{name} must be contiguous for this skeleton.\")\n",
        "\n",
        "\n",
        "def _make_additive_causal_mask(n: int, device, dtype):\n",
        "    \"\"\"\n",
        "    Returns additive mask M in shape [n, n]:\n",
        "      M[i, j] = 0 for j <= i\n",
        "      M[i, j] = -inf for j > i\n",
        "    Used as: scores = scores + M\n",
        "    \"\"\"\n",
        "    # TODO: implement causal mask creation\n",
        "    # raise NotImplementedError\n",
        "    if device is None:\n",
        "        device = \"cpu\"\n",
        "    if dtype is None:\n",
        "        dtype = torch.float32\n",
        "\n",
        "    # Use the minimum finite value for the dtype to represent \"-inf\" in practice.\n",
        "    # For fp16/bf16, true -inf exists, but using finfo.min is also common and safe.\n",
        "    # neg_inf = torch.finfo(dtype).min\n",
        "\n",
        "    # upper triangular (strictly above diagonal) => future positions\n",
        "    # shape [n, n], True where j > i\n",
        "    future = torch.triu(torch.ones((n, n), device=device, dtype=torch.bool), diagonal=1)\n",
        "\n",
        "    # start from zeros, fill future with neg_inf\n",
        "    mask = torch.zeros((n, n), device=device, dtype=dtype)\n",
        "    mask = mask.masked_fill(future, -float(\"inf\"))\n",
        "    return mask\n",
        "\n",
        "\n",
        "def _make_additive_padding_mask(valid_lens: torch.Tensor, n: int, device, dtype):\n",
        "    \"\"\"\n",
        "    valid_lens: [B] or [n] style lengths; for this Day2 skeleton we keep it simple:\n",
        "      - Assume a single sequence length n, and valid_lens is optional.\n",
        "      - If you want per-row masking, expand to [n, n] additive mask.\n",
        "      scores = scores + padding_mask\n",
        "    \"\"\"\n",
        "    # TODO: implement padding mask (optional)\n",
        "    # raise NotImplementedError\n",
        "    if device is None:\n",
        "        device = \"cpu\"\n",
        "    if dtype is None:\n",
        "        dtype = torch.float32\n",
        "\n",
        "    neg_inf = torch.finfo(dtype).min\n",
        "\n",
        "    # assume single length\n",
        "    if valid_lens is None:\n",
        "        return torch.zeros((n, n), device=device, dtype=dtype)\n",
        "\n",
        "    L = int(valid_lens.item())\n",
        "\n",
        "    # shape [n]\n",
        "    key_positions = torch.arange(n, device=device)\n",
        "\n",
        "    # True where j >= L\n",
        "    invalid = key_positions >= L\n",
        "\n",
        "    # expand to [n, n] (each row same mask)\n",
        "    invalid = invalid.unsqueeze(0).expand(n, n)\n",
        "\n",
        "    mask = torch.zeros((n, n), device=device, dtype=dtype)\n",
        "    mask = mask.masked_fill(invalid, neg_inf)\n",
        "\n",
        "    return mask\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Kernel 1: Scores = Q @ K^T\n",
        "# Q: [N, D], K: [N, D]  => Scores: [N, N]\n",
        "# ============================================================\n",
        "@triton.jit\n",
        "def qk_t_kernel(\n",
        "    q_ptr, k_ptr, s_ptr,\n",
        "    N: tl.constexpr, D: tl.constexpr,\n",
        "    stride_qn: tl.constexpr, stride_qd: tl.constexpr,\n",
        "    stride_kn: tl.constexpr, stride_kd: tl.constexpr,\n",
        "    stride_sn: tl.constexpr, stride_sm: tl.constexpr,\n",
        "    # Tile sizes (intentionally simple / naive)\n",
        "    BLOCK_M: tl.constexpr,\n",
        "    BLOCK_N: tl.constexpr,\n",
        "    BLOCK_K: tl.constexpr,\n",
        "):\n",
        "    \"\"\"\n",
        "    Compute a tile of S = QK^T.\n",
        "    Program ids map over (rows, cols) tiles of S.\n",
        "\n",
        "    TODO:\n",
        "    - Compute pid_m, pid_n\n",
        "    - Compute row/col offsets\n",
        "    - Load Q tile [BLOCK_M, BLOCK_K]\n",
        "    - Load K tile [BLOCK_N, BLOCK_K] (note K^T => K rows act like cols)\n",
        "    - Accumulate dot products\n",
        "    - Store to S\n",
        "    \"\"\"\n",
        "    # TODO: implement\n",
        "    tl.static_assert(BLOCK_K <= D,\n",
        "    \"BLOCK_K must be <= D for this skeleton\")\n",
        "    # raise NotImplementedError\n",
        "\n",
        "    # 2D program grid: each program handles a (BLOCK_M x BLOCK_N) tile of X\n",
        "    pid_m = tl.program_id(0)\n",
        "    pid_n = tl.program_id(1)\n",
        "\n",
        "    offs_m = pid_m * BLOCK_M + tl.arange(0, BLOCK_M)\n",
        "    offs_n = pid_n * BLOCK_N + tl.arange(0, BLOCK_N)\n",
        "    offs_k = tl.arange(0, BLOCK_K)\n",
        "\n",
        "\n",
        "    acc = tl.zeros((BLOCK_M, BLOCK_N), dtype=tl.float32)\n",
        "\n",
        "    m_mask = offs_m < N\n",
        "    n_mask = offs_n < N\n",
        "\n",
        "\n",
        "    for k0 in range(0, D, BLOCK_K):\n",
        "        d_offsets = k0 + offs_k\n",
        "        d_mask = d_offsets < D\n",
        "\n",
        "        q_ptrs = q_ptr + offs_m[:, None] * stride_qn + d_offsets[None, :] * stride_qd   # [BM, BK]\n",
        "        k_ptrs = k_ptr + offs_n[:, None] * stride_kn + d_offsets[None, :] * stride_kd  # [BN,BK]\n",
        "\n",
        "        # 2D masks for loads\n",
        "        q_load_mask = m_mask[:, None] & d_mask[None, :]    # [BM, BK]\n",
        "        k_load_mask = n_mask[:, None] & d_mask[None, :]    # [BK, BN]\n",
        "\n",
        "\n",
        "        q_tile = tl.load(q_ptrs, mask = q_load_mask, other = 0.0)\n",
        "        k_tile = tl.load(k_ptrs, mask = k_load_mask, other = 0.0)\n",
        "\n",
        "        acc += tl.dot(q_tile, tl.trans(k_tile))\n",
        "\n",
        "    s_ptrs = s_ptr + offs_m[:, None] * stride_sn + offs_n[None, :] * stride_sm\n",
        "    tl.store(s_ptrs, acc, mask = m_mask[:, None] & n_mask[None, :])\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Kernel 2: Softmax over each row of S (row-wise)\n",
        "# S: [N, N] -> P: [N, N]\n",
        "# Optional additive mask: M: [N, N] where invalid positions are -inf\n",
        "# ============================================================\n",
        "@triton.jit\n",
        "def softmax_row_kernel(\n",
        "    s_ptr, m_ptr, p_ptr,\n",
        "    N: tl.constexpr,\n",
        "    stride_sn: tl.constexpr, stride_sm: tl.constexpr,\n",
        "    stride_mn: tl.constexpr, stride_mm: tl.constexpr,\n",
        "    stride_pn: tl.constexpr, stride_pm: tl.constexpr,\n",
        "    BLOCK_N: tl.constexpr,\n",
        "    HAS_MASK: tl.constexpr,\n",
        "):\n",
        "    \"\"\"\n",
        "    Row-wise softmax:\n",
        "      p[i, :] = softmax(s[i, :] + mask[i, :])\n",
        "      p = s + m\n",
        "\n",
        "    TODO:\n",
        "    - Map program id to a row i\n",
        "    - Load a row block of scores\n",
        "    - If HAS_MASK, load mask and add\n",
        "    - Numerically stable softmax:\n",
        "        x = x - max(x)\n",
        "        exp = tl.exp(x)\n",
        "        denom = tl.sum(exp)\n",
        "        p = exp / denom\n",
        "    - Store p\n",
        "\n",
        "    Notes:\n",
        "    - This skeleton assumes N can be larger than BLOCK_N; you may loop over blocks\n",
        "      or restrict this Day2 to N <= BLOCK_N initially.\n",
        "    \"\"\"\n",
        "    # TODO: implement\n",
        "    # raise NotImplementedError\n",
        "    # if N > BLOCK_N:\n",
        "    #     raise ValueError(\"Naive row-softmax requires N <= BLOCK_N\")\n",
        "    pid_row = tl.program_id(0)\n",
        "    offs = tl.arange(0, BLOCK_N)\n",
        "\n",
        "    s_row_ptr = s_ptr + pid_row * stride_sn + offs * stride_sm\n",
        "    p_row_ptr = p_ptr + pid_row * stride_pn + offs * stride_pm\n",
        "\n",
        "    mask = offs < N\n",
        "    s_row = tl.load(s_row_ptr, mask = mask, other = -float(\"inf\")).to(tl.float32)\n",
        "    if HAS_MASK:\n",
        "        m_row_ptr = m_ptr + pid_row * stride_mn + offs * stride_mm\n",
        "        m_row = tl.load(m_row_ptr, mask = mask, other = 0.0).to(tl.float32)\n",
        "        s_row = s_row + m_row\n",
        "\n",
        "    # stable softmax\n",
        "    s_max = tl.max(s_row, axis = 0)\n",
        "    s_row = s_row - s_max\n",
        "    s_exp = tl.exp(s_row)\n",
        "    s_sum = tl.sum(s_exp, axis=0)\n",
        "    p_row = s_exp / s_sum\n",
        "\n",
        "    tl.store(p_row_ptr, p_row, mask = mask)\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Kernel 3: Out = P @ V\n",
        "# P: [N, N], V: [N, D] -> O: [N, D]\n",
        "# ============================================================\n",
        "@triton.jit\n",
        "def pv_kernel(\n",
        "    p_ptr, v_ptr, o_ptr,\n",
        "    N: tl.constexpr, D: tl.constexpr,\n",
        "    stride_pn: tl.constexpr, stride_pm: tl.constexpr,\n",
        "    stride_vn: tl.constexpr, stride_vd: tl.constexpr,\n",
        "    stride_on: tl.constexpr, stride_od: tl.constexpr,\n",
        "    BLOCK_M: tl.constexpr,\n",
        "    BLOCK_N: tl.constexpr,\n",
        "    BLOCK_K: tl.constexpr,\n",
        "):\n",
        "    \"\"\"\n",
        "    Compute a tile of O = P V.\n",
        "\n",
        "    TODO:\n",
        "    - Program ids over (rows of O, cols of O)\n",
        "    - Load P tile [BLOCK_M, BLOCK_K]\n",
        "    - Load V tile [BLOCK_K, BLOCK_N] (here K dimension is N of P / V rows)\n",
        "    - Accumulate\n",
        "    - Store to O\n",
        "    \"\"\"\n",
        "    # TODO: implement\n",
        "    # raise NotImplementedError\n",
        "    pid_m = tl.program_id(0)\n",
        "    pid_n = tl.program_id(1)\n",
        "\n",
        "    offs_m = pid_m * BLOCK_M + tl.arange(0, BLOCK_M)\n",
        "    offs_n = pid_n * BLOCK_N + tl.arange(0, BLOCK_N)\n",
        "    offs_k = tl.arange(0, BLOCK_K)\n",
        "\n",
        "    acc = tl.zeros((BLOCK_M, BLOCK_N), dtype=tl.float32)\n",
        "    m_mask = offs_m < N\n",
        "    n_mask = offs_n < D\n",
        "\n",
        "    for k0 in tl.static_range(0, N, BLOCK_K):\n",
        "          # current K indices for this chunk\n",
        "          k_offsets = k0 + offs_k\n",
        "          k_mask = k_offsets < N\n",
        "\n",
        "          # build pointer grids for this chunk\n",
        "          p_ptrs = p_ptr + offs_m[:, None] * stride_pn + k_offsets[None, :] * stride_pm\n",
        "          v_ptrs = v_ptr + k_offsets[:, None] * stride_vn + offs_n[None, :] * stride_vd\n",
        "\n",
        "          # 2D masks for loads\n",
        "          p_load_mask = m_mask[:, None] & k_mask[None, :]\n",
        "          v_load_mask = k_mask[:, None] & n_mask[None, :]\n",
        "\n",
        "          # masked loads: out-of-bounds => 0\n",
        "          p_tile = tl.load(p_ptrs, mask=p_load_mask, other=0).to(tl.float32)\n",
        "          v_tile = tl.load(v_ptrs, mask=v_load_mask, other=0).to(tl.float32)\n",
        "\n",
        "          # accumulate (fp32)\n",
        "          # tl.dot will typically accumulate in fp32 when acc is fp32\n",
        "          acc += tl.dot(p_tile, v_tile)\n",
        "\n",
        "    o_tile = acc\n",
        "    o_ptrs = o_ptr + offs_m[:, None] * stride_on + offs_n[None, :] * stride_od\n",
        "    tl.store(o_ptrs, o_tile, mask=m_mask[:,None] & n_mask[None,:])\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Launchers (NO SOLUTION)\n",
        "# ============================================================\n",
        "def qk_t_triton(Q: torch.Tensor, K: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Compute S = Q @ K^T\n",
        "    Q, K: [N, D] contiguous CUDA tensors\n",
        "    Returns:\n",
        "      S: [N, N]\n",
        "    \"\"\"\n",
        "    _assert_cuda(Q, \"Q\")\n",
        "    _assert_cuda(K, \"K\")\n",
        "    assert Q.shape == K.shape\n",
        "    N, D = Q.shape\n",
        "\n",
        "    S = torch.empty((N, N), device=Q.device, dtype=torch.float32)  # scores typically fp32\n",
        "\n",
        "    # TODO:\n",
        "    # - Choose BLOCK_M/BLOCK_N/BLOCK_K (naive defaults)\n",
        "    # - Define grid mapping over tiles\n",
        "    # - Call qk_t_kernel[grid](...)\n",
        "    # raise NotImplementedError\n",
        "    BLOCK_M = 128\n",
        "    BLOCK_N = 128\n",
        "    BLOCK_K = 64\n",
        "    # if N > BLOCK_N:\n",
        "    #     raise ValueError(\"Naive row-softmax requires N <= BLOCK_N\")\n",
        "\n",
        "    N, D = Q.shape\n",
        "    N2, D2 = K.shape\n",
        "    assert N == N2, \"Q and K must have the same sequence length\"\n",
        "    assert D == D2, \"Q and K must have the same head dimension\"\n",
        "\n",
        "    grid = (\n",
        "        triton.cdiv(N, BLOCK_M),\n",
        "        triton.cdiv(N, BLOCK_N),\n",
        "    )\n",
        "\n",
        "    qk_t_kernel[grid](\n",
        "        Q, K, S,\n",
        "        N = N, D = D,\n",
        "        stride_qn=Q.stride(0), stride_qd=Q.stride(1),\n",
        "        stride_kn=K.stride(0), stride_kd=K.stride(1),\n",
        "        stride_sn=S.stride(0), stride_sm=S.stride(1),\n",
        "        BLOCK_M=BLOCK_M, BLOCK_N=BLOCK_N, BLOCK_K=BLOCK_K)\n",
        "\n",
        "    return S\n",
        "\n",
        "\n",
        "def softmax_triton(S: torch.Tensor, mask: torch.Tensor | None) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Compute P = softmax(S + mask) row-wise.\n",
        "    S: [N, N]\n",
        "    mask: [N, N] additive mask (0 or -inf). If None, no mask.\n",
        "    Returns:\n",
        "      P: [N, N] (same dtype as S or fp16/fp32 choice)\n",
        "    \"\"\"\n",
        "    _assert_cuda(S, \"S\")\n",
        "    N, N2 = S.shape\n",
        "    assert N == N2\n",
        "\n",
        "    if mask is not None:\n",
        "        _assert_cuda(mask, \"mask\")\n",
        "        assert mask.shape == (N, N)\n",
        "\n",
        "    P = torch.empty_like(S)\n",
        "\n",
        "    # TODO:\n",
        "    # - Choose BLOCK_N\n",
        "    # - grid = (N,) one program per row (or per row-block)\n",
        "    # - HAS_MASK constexpr\n",
        "    # - Call softmax_row_kernel[grid](...)\n",
        "    # raise NotImplementedError\n",
        "    if N <= 128: BLOCK_N=128\n",
        "    elif N <= 256: BLOCK_N=256\n",
        "    elif N <= 512: BLOCK_N=512\n",
        "    elif N <= 1024: BLOCK_N=1024\n",
        "    else:\n",
        "        raise ValueError(f\"Naive row-softmax requires N <= 1024, got N={N}\")\n",
        "    grid = (N,)\n",
        "\n",
        "    HAS_MASK = mask is not None\n",
        "    m_ptr = mask if HAS_MASK else S\n",
        "    stride_mn = mask.stride(0) if HAS_MASK else 0\n",
        "    stride_mm = mask.stride(1) if HAS_MASK else 0\n",
        "\n",
        "\n",
        "    softmax_row_kernel[grid](\n",
        "    S, m_ptr, P,\n",
        "    N,\n",
        "    S.stride(0), S.stride(1),\n",
        "    stride_mn, stride_mm,\n",
        "    P.stride(0), P.stride(1),\n",
        "    BLOCK_N=BLOCK_N,\n",
        "    HAS_MASK=HAS_MASK,\n",
        ")\n",
        "\n",
        "\n",
        "    return P\n",
        "\n",
        "\n",
        "def pv_triton(P: torch.Tensor, V: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Compute O = P @ V\n",
        "    P: [N, N]\n",
        "    V: [N, D]\n",
        "    Returns:\n",
        "      O: [N, D]\n",
        "    \"\"\"\n",
        "    _assert_cuda(P, \"P\")\n",
        "    _assert_cuda(V, \"V\")\n",
        "    N, N2 = P.shape\n",
        "    assert N == N2\n",
        "    assert V.shape[0] == N\n",
        "    D = V.shape[1]\n",
        "\n",
        "    O = torch.empty((N, D), device=V.device, dtype=torch.float32)\n",
        "\n",
        "    # TODO:\n",
        "    # - Choose BLOCK_M/BLOCK_N/BLOCK_K\n",
        "    # - Define grid over O tiles\n",
        "    # - Call pv_kernel[grid](...)\n",
        "    # raise NotImplementedError\n",
        "    BLOCK_M = 128\n",
        "    BLOCK_N = 128\n",
        "    BLOCK_K = 64\n",
        "\n",
        "    grid = (\n",
        "        triton.cdiv(N, BLOCK_M),  # pid_m\n",
        "        triton.cdiv(D, BLOCK_N),  # pid_n\n",
        "    )\n",
        "\n",
        "    pv_kernel[grid](\n",
        "        P, V, O,\n",
        "        N=N, D=D,\n",
        "        stride_pn=P.stride(0), stride_pm=P.stride(1),\n",
        "        stride_vn=V.stride(0), stride_vd=V.stride(1),\n",
        "        stride_on=O.stride(0), stride_od=O.stride(1),\n",
        "        BLOCK_M=BLOCK_M,\n",
        "        BLOCK_N=BLOCK_N,\n",
        "        BLOCK_K=BLOCK_K)\n",
        "\n",
        "    return O\n",
        "\n",
        "def naive_attention_triton(Q: torch.Tensor, K: torch.Tensor, V: torch.Tensor, mask: torch.Tensor | None = None):\n",
        "    \"\"\"\n",
        "    Full naive attention:\n",
        "      S = QK^T\n",
        "      P = softmax(S + mask)\n",
        "      O = P V\n",
        "    \"\"\"\n",
        "    # TODO:\n",
        "    # - Call qk_t_triton\n",
        "    # - Call softmax_triton\n",
        "    # - Call pv_triton\n",
        "    # raise NotImplementedError\n",
        "    _assert_cuda(Q, \"Q\")\n",
        "    _assert_cuda(K, \"K\")\n",
        "    _assert_cuda(V, \"V\")\n",
        "    assert Q.shape == K.shape, \"Q and K must have shape [N, D]\"\n",
        "    assert Q.shape == V.shape, \"For this toy naive version, assume V has shape [N, D]\"\n",
        "    N, D = Q.shape\n",
        "\n",
        "    if mask is not None:\n",
        "        _assert_cuda(mask, \"mask\")\n",
        "        assert mask.shape == (N, N), \"mask must be [N, N] additive mask (0 / -inf)\"\n",
        "\n",
        "    # 1) Scores: S = Q @ K^T   -> [N, N] (often fp32)\n",
        "    S = qk_t_triton(Q, K)\n",
        "\n",
        "    # 2) Probabilities: P = softmax(S + mask)  -> [N, N]\n",
        "    P = softmax_triton(S, mask)\n",
        "\n",
        "    # 3) Output: O = P @ V     -> [N, D]\n",
        "    O = pv_triton(P, V)\n",
        "\n",
        "    return O\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# PyTorch reference & correctness checks (NO SOLUTION)\n",
        "# ============================================================\n",
        "def naive_attention_torch(Q: torch.Tensor, K: torch.Tensor, V: torch.Tensor, mask: torch.Tensor | None = None):\n",
        "    \"\"\"\n",
        "    Reference implementation in PyTorch:\n",
        "      attn = softmax(Q @ K.T + mask) @ V\n",
        "    \"\"\"\n",
        "    # TODO: implement torch reference (use float32 accumulation if needed)\n",
        "    # raise NotImplementedError\n",
        "    assert Q.shape == K.shape == V.shape, \"This toy reference assumes Q,K,V are all [N, D]\"\n",
        "    N, D = Q.shape\n",
        "\n",
        "    # Use fp32 for scores/softmax stability, regardless of input dtype\n",
        "    Qf = Q.to(torch.float32)\n",
        "    Kf = K.to(torch.float32)\n",
        "    Vf = V.to(torch.float32)\n",
        "\n",
        "    scores = Qf @ Kf.transpose(0, 1)  # [N, N]\n",
        "\n",
        "    if mask is not None:\n",
        "        assert mask.shape == (N, N), f\"mask must be [N, N], got {mask.shape}\"\n",
        "        scores = scores + mask.to(torch.float32)\n",
        "\n",
        "    P = torch.softmax(scores, dim=-1)  # row-wise softmax\n",
        "    O = P @ Vf  # [N, D]\n",
        "\n",
        "    return O\n",
        "\n",
        "@torch.no_grad()\n",
        "def check_correctness(device=\"cuda\", dtype=torch.float16, N=256, D=64, use_mask=True):\n",
        "    torch.manual_seed(0)\n",
        "    Q = torch.randn((N, D), device=device, dtype=dtype)\n",
        "    K = torch.randn((N, D), device=device, dtype=dtype)\n",
        "    V = torch.randn((N, D), device=device, dtype=dtype)\n",
        "\n",
        "    mask = None\n",
        "    if use_mask:\n",
        "        # TODO: create a causal mask (or padding mask)\n",
        "        mask = _make_additive_causal_mask(N, device=device, dtype=torch.float32)\n",
        "\n",
        "    # TODO:\n",
        "    # - Run torch reference\n",
        "    # - Run triton naive attention\n",
        "    # - Compare max/mean error\n",
        "    # raise NotImplementedError\n",
        "    # Reference (PyTorch)\n",
        "    out_ref = naive_attention_torch(Q, K, V, mask=mask)\n",
        "\n",
        "    # Triton naive\n",
        "    out_tri = naive_attention_triton(Q, K, V, mask=mask)\n",
        "\n",
        "    # Compare (cast both to fp32 for fair error)\n",
        "    diff = (out_tri.to(torch.float32) - out_ref.to(torch.float32)).abs()\n",
        "    max_err = diff.max().item()\n",
        "    mean_err = diff.mean().item()\n",
        "    rmse = torch.sqrt((diff * diff).mean()).item()\n",
        "\n",
        "    print(f\"[check_correctness] N={N}, D={D}, dtype={dtype}, use_mask={use_mask}\")\n",
        "    print(f\"  max_abs_err : {max_err:.6e}\")\n",
        "    print(f\"  mean_abs_err: {mean_err:.6e}\")\n",
        "    print(f\"  rmse        : {rmse:.6e}\")\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def quick_bench(device=\"cuda\", dtype=torch.float16, N=1024, D=64, iters=50, warmup=10, use_mask=False):\n",
        "    \"\"\"\n",
        "    Simple benchmark harness (intentionally minimal).\n",
        "    \"\"\"\n",
        "    Q = torch.randn((N, D), device=device, dtype=dtype)\n",
        "    K = torch.randn((N, D), device=device, dtype=dtype)\n",
        "    V = torch.randn((N, D), device=device, dtype=dtype)\n",
        "\n",
        "    mask = None\n",
        "    if use_mask:\n",
        "        # TODO: create mask\n",
        "        mask = _make_additive_causal_mask(N, device=device, dtype=torch.float32)\n",
        "\n",
        "    # TODO:\n",
        "    # - Warmup runs\n",
        "    # - Time with CUDA events\n",
        "    # - Print ms/iter for torch vs triton\n",
        "    # raise NotImplementedError\n",
        "    torch.manual_seed(0)\n",
        "\n",
        "    Q = torch.randn((N, D), device=device, dtype=dtype)\n",
        "    K = torch.randn((N, D), device=device, dtype=dtype)\n",
        "    V = torch.randn((N, D), device=device, dtype=dtype)\n",
        "\n",
        "    mask = None\n",
        "    if use_mask:\n",
        "        # Additive causal mask: 0 or -inf\n",
        "        mask = _make_additive_causal_mask(N, device=device, dtype=torch.float32)\n",
        "\n",
        "    # ----------------------------\n",
        "    # Warmup\n",
        "    # ----------------------------\n",
        "    for _ in range(warmup):\n",
        "        naive_attention_triton(Q, K, V, mask=mask)\n",
        "        naive_attention_torch(Q, K, V, mask=mask)\n",
        "    torch.cuda.synchronize()\n",
        "\n",
        "    # ----------------------------\n",
        "    # Benchmark Triton\n",
        "    # ----------------------------\n",
        "    start = torch.cuda.Event(enable_timing=True)\n",
        "    end = torch.cuda.Event(enable_timing=True)\n",
        "\n",
        "    start.record()\n",
        "    for _ in range(iters):\n",
        "        naive_attention_triton(Q, K, V, mask=mask)\n",
        "    end.record()\n",
        "    torch.cuda.synchronize()\n",
        "\n",
        "    triton_ms = start.elapsed_time(end) / iters\n",
        "\n",
        "    # ----------------------------\n",
        "    # Benchmark Torch\n",
        "    # ----------------------------\n",
        "    start.record()\n",
        "    for _ in range(iters):\n",
        "        naive_attention_torch(Q, K, V, mask=mask)\n",
        "    end.record()\n",
        "    torch.cuda.synchronize()\n",
        "\n",
        "    torch_ms = start.elapsed_time(end) / iters\n",
        "\n",
        "    speedup = torch_ms / triton_ms\n",
        "\n",
        "    print(f\"\\n[quick_bench]\")\n",
        "    print(f\"N={N}, D={D}, dtype={dtype}, mask={use_mask}\")\n",
        "    print(f\"Triton: {triton_ms:.3f} ms\")\n",
        "    print(f\"Torch : {torch_ms:.3f} ms\")\n",
        "    print(f\"Speedup (Torch/Triton): {speedup:.2f}x\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # TODO: run correctness + small bench\n",
        "    check_correctness(N=128, D=64, use_mask=True)\n",
        "    quick_bench(N=1024, D=64, use_mask=False)\n",
        "    # pass\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# triton_naive_attention_skeleton.py\n",
        "# ============================================================\n",
        "# Day 2 ‚Äî Triton Naive Attention Kernel (NO SOLUTION)\n",
        "# Goal:\n",
        "  #improvement:1. change qk_t_kernel to uncoalscing reading on K demension(lower performance)\n",
        "  # 2. softmax change the accuracy to bf16 0.04x to 0.14x\n",
        "  # 3. softmax 2 pass kernel Pass1: row maxÔºõPass2: sum(exp) + store(lower performance)\n",
        "\n",
        "# ============================================================\n",
        "\n",
        "import math\n",
        "import torch\n",
        "import triton\n",
        "import triton.language as tl\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Utilities\n",
        "# -----------------------------\n",
        "def _assert_cuda(x: torch.Tensor, name: str):\n",
        "    if not x.is_cuda:\n",
        "        raise ValueError(f\"{name} must be on CUDA, got {x.device}\")\n",
        "    if not x.is_contiguous():\n",
        "        raise ValueError(f\"{name} must be contiguous for this skeleton.\")\n",
        "\n",
        "\n",
        "def _make_additive_causal_mask(n: int, device, dtype):\n",
        "    \"\"\"\n",
        "    Returns additive mask M in shape [n, n]:\n",
        "      M[i, j] = 0 for j <= i\n",
        "      M[i, j] = -inf for j > i\n",
        "    Used as: scores = scores + M\n",
        "    \"\"\"\n",
        "    # TODO: implement causal mask creation\n",
        "    # raise NotImplementedError\n",
        "    if device is None:\n",
        "        device = \"cpu\"\n",
        "    if dtype is None:\n",
        "        dtype = torch.float32\n",
        "\n",
        "    # Use the minimum finite value for the dtype to represent \"-inf\" in practice.\n",
        "    # For fp16/bf16, true -inf exists, but using finfo.min is also common and safe.\n",
        "    # neg_inf = torch.finfo(dtype).min\n",
        "\n",
        "    # upper triangular (strictly above diagonal) => future positions\n",
        "    # shape [n, n], True where j > i\n",
        "    future = torch.triu(torch.ones((n, n), device=device, dtype=torch.bool), diagonal=1)\n",
        "\n",
        "    # start from zeros, fill future with neg_inf\n",
        "    mask = torch.zeros((n, n), device=device, dtype=dtype)\n",
        "    mask = mask.masked_fill(future, -float(\"inf\"))\n",
        "    return mask\n",
        "\n",
        "\n",
        "def _make_additive_padding_mask(valid_lens: torch.Tensor, n: int, device, dtype):\n",
        "    \"\"\"\n",
        "    valid_lens: [B] or [n] style lengths; for this Day2 skeleton we keep it simple:\n",
        "      - Assume a single sequence length n, and valid_lens is optional.\n",
        "      - If you want per-row masking, expand to [n, n] additive mask.\n",
        "      scores = scores + padding_mask\n",
        "    \"\"\"\n",
        "    # TODO: implement padding mask (optional)\n",
        "    # raise NotImplementedError\n",
        "    if device is None:\n",
        "        device = \"cpu\"\n",
        "    if dtype is None:\n",
        "        dtype = torch.float32\n",
        "\n",
        "    neg_inf = torch.finfo(dtype).min\n",
        "\n",
        "    # assume single length\n",
        "    if valid_lens is None:\n",
        "        return torch.zeros((n, n), device=device, dtype=dtype)\n",
        "\n",
        "    L = int(valid_lens.item())\n",
        "\n",
        "    # shape [n]\n",
        "    key_positions = torch.arange(n, device=device)\n",
        "\n",
        "    # True where j >= L\n",
        "    invalid = key_positions >= L\n",
        "\n",
        "    # expand to [n, n] (each row same mask)\n",
        "    invalid = invalid.unsqueeze(0).expand(n, n)\n",
        "\n",
        "    mask = torch.zeros((n, n), device=device, dtype=dtype)\n",
        "    mask = mask.masked_fill(invalid, neg_inf)\n",
        "\n",
        "    return mask\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Kernel 1: Scores = Q @ K^T\n",
        "# Q: [N, D], K: [N, D]  => Scores: [N, N]\n",
        "# ============================================================\n",
        "@triton.jit\n",
        "def qk_t_kernel(\n",
        "    q_ptr, k_ptr, s_ptr,\n",
        "    N: tl.constexpr, D: tl.constexpr,\n",
        "    stride_qn: tl.constexpr, stride_qd: tl.constexpr,\n",
        "    stride_kn: tl.constexpr, stride_kd: tl.constexpr,\n",
        "    stride_sn: tl.constexpr, stride_sm: tl.constexpr,\n",
        "    # Tile sizes (intentionally simple / naive)\n",
        "    BLOCK_M: tl.constexpr,\n",
        "    BLOCK_N: tl.constexpr,\n",
        "    BLOCK_K: tl.constexpr,\n",
        "):\n",
        "    \"\"\"\n",
        "    Compute a tile of S = QK^T.\n",
        "    Program ids map over (rows, cols) tiles of S.\n",
        "\n",
        "    TODO:\n",
        "    - Compute pid_m, pid_n\n",
        "    - Compute row/col offsets\n",
        "    - Load Q tile [BLOCK_M, BLOCK_K]\n",
        "    - Load K tile [BLOCK_N, BLOCK_K] (note K^T => K rows act like cols)\n",
        "    - Accumulate dot products\n",
        "    - Store to S\n",
        "    \"\"\"\n",
        "    # TODO: implement\n",
        "    tl.static_assert(BLOCK_K <= D,\n",
        "    \"BLOCK_K must be <= D for this skeleton\")\n",
        "    # raise NotImplementedError\n",
        "\n",
        "    # 2D program grid: each program handles a (BLOCK_M x BLOCK_N) tile of X\n",
        "    pid_m = tl.program_id(0)\n",
        "    pid_n = tl.program_id(1)\n",
        "\n",
        "    offs_m = pid_m * BLOCK_M + tl.arange(0, BLOCK_M)\n",
        "    offs_n = pid_n * BLOCK_N + tl.arange(0, BLOCK_N)\n",
        "    offs_k = tl.arange(0, BLOCK_K)\n",
        "\n",
        "\n",
        "    acc = tl.zeros((BLOCK_M, BLOCK_N), dtype=tl.float32)\n",
        "\n",
        "    m_mask = offs_m < N\n",
        "    n_mask = offs_n < N\n",
        "\n",
        "\n",
        "    for k0 in range(0, D, BLOCK_K):\n",
        "        d_offsets = k0 + offs_k\n",
        "        d_mask = d_offsets < D\n",
        "\n",
        "        q_ptrs = q_ptr + offs_m[:, None] * stride_qn + d_offsets[None, :] * stride_qd   # [BM, BK]\n",
        "        k_ptrs = k_ptr + offs_n[:, None] * stride_kn + d_offsets[None, :] * stride_kd  # [BN,BK]\n",
        "\n",
        "        # 2D masks for loads\n",
        "        q_load_mask = m_mask[:, None] & d_mask[None, :]    # [BM, BK]\n",
        "        k_load_mask = n_mask[:, None] & d_mask[None, :]    # [BK, BN]\n",
        "\n",
        "\n",
        "        q_tile = tl.load(q_ptrs, mask = q_load_mask, other = 0.0)\n",
        "        k_tile = tl.load(k_ptrs, mask = k_load_mask, other = 0.0)\n",
        "\n",
        "        acc += tl.dot(q_tile, tl.trans(k_tile))\n",
        "\n",
        "    s_ptrs = s_ptr + offs_m[:, None] * stride_sn + offs_n[None, :] * stride_sm\n",
        "    tl.store(s_ptrs, acc, mask = m_mask[:, None] & n_mask[None, :])\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Kernel 2: Softmax over each row of S (row-wise)\n",
        "# S: [N, N] -> P: [N, N]\n",
        "# Optional additive mask: M: [N, N] where invalid positions are -inf\n",
        "# ============================================================\n",
        "@triton.jit\n",
        "def softmax_row_kernel(\n",
        "    s_ptr, m_ptr, p_ptr,\n",
        "    N: tl.constexpr,\n",
        "    stride_sn: tl.constexpr, stride_sm: tl.constexpr,\n",
        "    stride_mn: tl.constexpr, stride_mm: tl.constexpr,\n",
        "    stride_pn: tl.constexpr, stride_pm: tl.constexpr,\n",
        "    BLOCK_N: tl.constexpr,\n",
        "    HAS_MASK: tl.constexpr,\n",
        "):\n",
        "    \"\"\"\n",
        "    Row-wise softmax:\n",
        "      p[i, :] = softmax(s[i, :] + mask[i, :])\n",
        "      p = s + m\n",
        "\n",
        "    TODO:\n",
        "    - Map program id to a row i\n",
        "    - Load a row block of scores\n",
        "    - If HAS_MASK, load mask and add\n",
        "    - Numerically stable softmax:\n",
        "        x = x - max(x)\n",
        "        exp = tl.exp(x)\n",
        "        denom = tl.sum(exp)\n",
        "        p = exp / denom\n",
        "    - Store p\n",
        "\n",
        "    Notes:\n",
        "    - This skeleton assumes N can be larger than BLOCK_N; you may loop over blocks\n",
        "      or restrict this Day2 to N <= BLOCK_N initially.\n",
        "    \"\"\"\n",
        "    # TODO: implement\n",
        "    # 2-pass row-wise softmax for a single row per program.\n",
        "\n",
        "    # Pass 1: row_max = max_j (s[row, j] + mask[row, j])\n",
        "    # Pass 2: row_sum = sum_j exp(s[row, j] + mask[row, j] - row_max)\n",
        "    #         write p[row, j] = exp(...) / row_sum\n",
        "    pid_row = tl.program_id(0)\n",
        "    # ----------------------------\n",
        "    # Pass 1: compute row max\n",
        "    # ----------------------------\n",
        "    row_max = tl.full((), -float(\"inf\"), tl.float32)\n",
        "\n",
        "    # loop over columns in blocks\n",
        "    for c0 in range(0, N, BLOCK_N):\n",
        "        offs = c0 + tl.arange(0, BLOCK_N)\n",
        "        col_mask = offs < N\n",
        "\n",
        "        s_row_ptr = s_ptr + pid_row * stride_sn + offs * stride_sm\n",
        "        x = tl.load(s_row_ptr, mask=col_mask, other=-float(\"inf\")).to(tl.float32)\n",
        "\n",
        "        if HAS_MASK:\n",
        "            m_row_ptr = m_ptr + pid_row * stride_mn + offs * stride_mm\n",
        "            m = tl.load(m_row_ptr, mask=col_mask, other=0.0).to(tl.float32)\n",
        "            x = x + m\n",
        "\n",
        "        block_max = tl.max(x, axis=0)\n",
        "        row_max = tl.maximum(row_max, block_max)\n",
        "\n",
        "    # ----------------------------\n",
        "    # Pass 2: compute sum(exp) and write output\n",
        "    # ----------------------------\n",
        "    row_sum = tl.zeros((), dtype=tl.float32)\n",
        "\n",
        "    # 2a) sum\n",
        "    for c0 in range(0, N, BLOCK_N):\n",
        "        offs = c0 + tl.arange(0, BLOCK_N)\n",
        "        col_mask = offs < N\n",
        "\n",
        "        s_row_ptr = s_ptr + pid_row * stride_sn + offs * stride_sm\n",
        "        x = tl.load(s_row_ptr, mask=col_mask, other=-float(\"inf\")).to(tl.float32)\n",
        "\n",
        "        if HAS_MASK:\n",
        "            m_row_ptr = m_ptr + pid_row * stride_mn + offs * stride_mm\n",
        "            m = tl.load(m_row_ptr, mask=col_mask, other=0.0).to(tl.float32)\n",
        "            x = x + m\n",
        "\n",
        "        x = x - row_max\n",
        "        exp_x = tl.exp(x)\n",
        "        row_sum += tl.sum(exp_x, axis=0)\n",
        "\n",
        "    # 2b) write\n",
        "    inv_sum = 1.0 / row_sum\n",
        "    for c0 in range(0, N, BLOCK_N):\n",
        "        offs = c0 + tl.arange(0, BLOCK_N)\n",
        "        col_mask = offs < N\n",
        "\n",
        "        s_row_ptr = s_ptr + pid_row * stride_sn + offs * stride_sm\n",
        "        x = tl.load(s_row_ptr, mask=col_mask, other=-float(\"inf\")).to(tl.float32)\n",
        "\n",
        "        if HAS_MASK:\n",
        "            m_row_ptr = m_ptr + pid_row * stride_mn + offs * stride_mm\n",
        "            m = tl.load(m_row_ptr, mask=col_mask, other=0.0).to(tl.float32)\n",
        "            x = x + m\n",
        "\n",
        "        x = x - row_max\n",
        "        p = tl.exp(x) * inv_sum  # fp32\n",
        "\n",
        "        p_row_ptr = p_ptr + pid_row * stride_pn + offs * stride_pm\n",
        "        tl.store(p_row_ptr, p.to(tl.float16), mask=col_mask)\n",
        "\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Kernel 3: Out = P @ V\n",
        "# P: [N, N], V: [N, D] -> O: [N, D]\n",
        "# ============================================================\n",
        "@triton.jit\n",
        "def pv_kernel(\n",
        "    p_ptr, v_ptr, o_ptr,\n",
        "    N: tl.constexpr, D: tl.constexpr,\n",
        "    stride_pn: tl.constexpr, stride_pm: tl.constexpr,\n",
        "    stride_vn: tl.constexpr, stride_vd: tl.constexpr,\n",
        "    stride_on: tl.constexpr, stride_od: tl.constexpr,\n",
        "    BLOCK_M: tl.constexpr,\n",
        "    BLOCK_N: tl.constexpr,\n",
        "    BLOCK_K: tl.constexpr,\n",
        "):\n",
        "    \"\"\"\n",
        "    Compute a tile of O = P V.\n",
        "\n",
        "    TODO:\n",
        "    - Program ids over (rows of O, cols of O)\n",
        "    - Load P tile [BLOCK_M, BLOCK_K]\n",
        "    - Load V tile [BLOCK_K, BLOCK_N] (here K dimension is N of P / V rows)\n",
        "    - Accumulate\n",
        "    - Store to O\n",
        "    \"\"\"\n",
        "    # TODO: implement\n",
        "    # raise NotImplementedError\n",
        "    pid_m = tl.program_id(0)\n",
        "    pid_n = tl.program_id(1)\n",
        "\n",
        "    offs_m = pid_m * BLOCK_M + tl.arange(0, BLOCK_M)\n",
        "    offs_n = pid_n * BLOCK_N + tl.arange(0, BLOCK_N)\n",
        "    offs_k = tl.arange(0, BLOCK_K)\n",
        "\n",
        "    acc = tl.zeros((BLOCK_M, BLOCK_N), dtype=tl.float32)\n",
        "    m_mask = offs_m < N\n",
        "    n_mask = offs_n < D\n",
        "\n",
        "    for k0 in tl.static_range(0, N, BLOCK_K):\n",
        "          # current K indices for this chunk\n",
        "          k_offsets = k0 + offs_k\n",
        "          k_mask = k_offsets < N\n",
        "\n",
        "          # build pointer grids for this chunk\n",
        "          p_ptrs = p_ptr + offs_m[:, None] * stride_pn + k_offsets[None, :] * stride_pm\n",
        "          v_ptrs = v_ptr + k_offsets[:, None] * stride_vn + offs_n[None, :] * stride_vd\n",
        "\n",
        "          # 2D masks for loads\n",
        "          p_load_mask = m_mask[:, None] & k_mask[None, :]\n",
        "          v_load_mask = k_mask[:, None] & n_mask[None, :]\n",
        "\n",
        "          # masked loads: out-of-bounds => 0\n",
        "          p_tile = tl.load(p_ptrs, mask=p_load_mask, other=0).to(tl.float32)\n",
        "          v_tile = tl.load(v_ptrs, mask=v_load_mask, other=0).to(tl.float32)\n",
        "\n",
        "          # accumulate (fp32)\n",
        "          # tl.dot will typically accumulate in fp32 when acc is fp32\n",
        "          acc += tl.dot(p_tile, v_tile)\n",
        "\n",
        "    o_tile = acc\n",
        "    o_ptrs = o_ptr + offs_m[:, None] * stride_on + offs_n[None, :] * stride_od\n",
        "    tl.store(o_ptrs, o_tile, mask=m_mask[:,None] & n_mask[None,:])\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Launchers (NO SOLUTION)\n",
        "# ============================================================\n",
        "def qk_t_triton(Q: torch.Tensor, K: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Compute S = Q @ K^T\n",
        "    Q, K: [N, D] contiguous CUDA tensors\n",
        "    Returns:\n",
        "      S: [N, N]\n",
        "    \"\"\"\n",
        "    _assert_cuda(Q, \"Q\")\n",
        "    _assert_cuda(K, \"K\")\n",
        "    assert Q.shape == K.shape\n",
        "    N, D = Q.shape\n",
        "\n",
        "    S = torch.empty((N, N), device=Q.device, dtype=torch.float32)  # scores typically fp32\n",
        "\n",
        "    # TODO:\n",
        "    # - Choose BLOCK_M/BLOCK_N/BLOCK_K (naive defaults)\n",
        "    # - Define grid mapping over tiles\n",
        "    # - Call qk_t_kernel[grid](...)\n",
        "    # raise NotImplementedError\n",
        "    BLOCK_M = 128\n",
        "    BLOCK_N = 128\n",
        "    BLOCK_K = 64\n",
        "    # if N > BLOCK_N:\n",
        "    #     raise ValueError(\"Naive row-softmax requires N <= BLOCK_N\")\n",
        "\n",
        "    N, D = Q.shape\n",
        "    N2, D2 = K.shape\n",
        "    assert N == N2, \"Q and K must have the same sequence length\"\n",
        "    assert D == D2, \"Q and K must have the same head dimension\"\n",
        "\n",
        "    grid = (\n",
        "        triton.cdiv(N, BLOCK_M),\n",
        "        triton.cdiv(N, BLOCK_N),\n",
        "    )\n",
        "\n",
        "    qk_t_kernel[grid](\n",
        "        Q, K, S,\n",
        "        N = N, D = D,\n",
        "        stride_qn=Q.stride(0), stride_qd=Q.stride(1),\n",
        "        stride_kn=K.stride(0), stride_kd=K.stride(1),\n",
        "        stride_sn=S.stride(0), stride_sm=S.stride(1),\n",
        "        BLOCK_M=BLOCK_M, BLOCK_N=BLOCK_N, BLOCK_K=BLOCK_K)\n",
        "\n",
        "    return S\n",
        "\n",
        "\n",
        "def softmax_triton(S: torch.Tensor, mask: torch.Tensor | None) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Compute P = softmax(S + mask) row-wise.\n",
        "    S: [N, N]\n",
        "    mask: [N, N] additive mask (0 or -inf). If None, no mask.\n",
        "    Returns:\n",
        "      P: [N, N] (same dtype as S or fp16/fp32 choice)\n",
        "    \"\"\"\n",
        "    _assert_cuda(S, \"S\")\n",
        "    N, N2 = S.shape\n",
        "    assert N == N2\n",
        "\n",
        "    if mask is not None:\n",
        "        _assert_cuda(mask, \"mask\")\n",
        "        assert mask.shape == (N, N)\n",
        "\n",
        "    # P = torch.empty_like(S)\n",
        "    P = torch.empty((N, N), device=S.device, dtype=torch.float16)\n",
        "\n",
        "    # TODO:\n",
        "    # - Choose BLOCK_N\n",
        "    # - grid = (N,) one program per row (or per row-block)\n",
        "    # - HAS_MASK constexpr\n",
        "    # - Call softmax_row_kernel[grid](...)\n",
        "    # raise NotImplementedError\n",
        "    if N <= 128: BLOCK_N=128\n",
        "    elif N <= 256: BLOCK_N=256\n",
        "    elif N <= 512: BLOCK_N=512\n",
        "    elif N <= 1024: BLOCK_N=1024\n",
        "    else:\n",
        "        raise ValueError(f\"Naive row-softmax requires N <= 1024, got N={N}\")\n",
        "    grid = (N,)\n",
        "\n",
        "    HAS_MASK = mask is not None\n",
        "    m_ptr = mask if HAS_MASK else S\n",
        "    stride_mn = mask.stride(0) if HAS_MASK else 0\n",
        "    stride_mm = mask.stride(1) if HAS_MASK else 0\n",
        "\n",
        "\n",
        "    softmax_row_kernel[grid](\n",
        "    S, m_ptr, P,\n",
        "    N,\n",
        "    S.stride(0), S.stride(1),\n",
        "    stride_mn, stride_mm,\n",
        "    P.stride(0), P.stride(1),\n",
        "    BLOCK_N=BLOCK_N,\n",
        "    HAS_MASK=HAS_MASK,\n",
        ")\n",
        "\n",
        "\n",
        "    return P\n",
        "\n",
        "\n",
        "def pv_triton(P: torch.Tensor, V: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Compute O = P @ V\n",
        "    P: [N, N]\n",
        "    V: [N, D]\n",
        "    Returns:\n",
        "      O: [N, D]\n",
        "    \"\"\"\n",
        "    _assert_cuda(P, \"P\")\n",
        "    _assert_cuda(V, \"V\")\n",
        "    N, N2 = P.shape\n",
        "    assert N == N2\n",
        "    assert V.shape[0] == N\n",
        "    D = V.shape[1]\n",
        "\n",
        "    O = torch.empty((N, D), device=V.device, dtype=torch.float32)\n",
        "\n",
        "    # TODO:\n",
        "    # - Choose BLOCK_M/BLOCK_N/BLOCK_K\n",
        "    # - Define grid over O tiles\n",
        "    # - Call pv_kernel[grid](...)\n",
        "    # raise NotImplementedError\n",
        "    BLOCK_M = 128\n",
        "    BLOCK_N = 128\n",
        "    BLOCK_K = 64\n",
        "\n",
        "    grid = (\n",
        "        triton.cdiv(N, BLOCK_M),  # pid_m\n",
        "        triton.cdiv(D, BLOCK_N),  # pid_n\n",
        "    )\n",
        "\n",
        "    pv_kernel[grid](\n",
        "        P, V, O,\n",
        "        N=N, D=D,\n",
        "        stride_pn=P.stride(0), stride_pm=P.stride(1),\n",
        "        stride_vn=V.stride(0), stride_vd=V.stride(1),\n",
        "        stride_on=O.stride(0), stride_od=O.stride(1),\n",
        "        BLOCK_M=BLOCK_M,\n",
        "        BLOCK_N=BLOCK_N,\n",
        "        BLOCK_K=BLOCK_K)\n",
        "\n",
        "    return O\n",
        "\n",
        "def naive_attention_triton(Q: torch.Tensor, K: torch.Tensor, V: torch.Tensor, mask: torch.Tensor | None = None):\n",
        "    \"\"\"\n",
        "    Full naive attention:\n",
        "      S = QK^T\n",
        "      P = softmax(S + mask)\n",
        "      O = P V\n",
        "    \"\"\"\n",
        "    # TODO:\n",
        "    # - Call qk_t_triton\n",
        "    # - Call softmax_triton\n",
        "    # - Call pv_triton\n",
        "    # raise NotImplementedError\n",
        "    _assert_cuda(Q, \"Q\")\n",
        "    _assert_cuda(K, \"K\")\n",
        "    _assert_cuda(V, \"V\")\n",
        "    assert Q.shape == K.shape, \"Q and K must have shape [N, D]\"\n",
        "    assert Q.shape == V.shape, \"For this toy naive version, assume V has shape [N, D]\"\n",
        "    N, D = Q.shape\n",
        "\n",
        "    if mask is not None:\n",
        "        _assert_cuda(mask, \"mask\")\n",
        "        assert mask.shape == (N, N), \"mask must be [N, N] additive mask (0 / -inf)\"\n",
        "\n",
        "    # 1) Scores: S = Q @ K^T   -> [N, N] (often fp32)\n",
        "    S = qk_t_triton(Q, K)\n",
        "\n",
        "    # 2) Probabilities: P = softmax(S + mask)  -> [N, N]\n",
        "    P = softmax_triton(S, mask)\n",
        "\n",
        "    # 3) Output: O = P @ V     -> [N, D]\n",
        "    O = pv_triton(P, V)\n",
        "\n",
        "    return O\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# PyTorch reference & correctness checks (NO SOLUTION)\n",
        "# ============================================================\n",
        "def naive_attention_torch(Q: torch.Tensor, K: torch.Tensor, V: torch.Tensor, mask: torch.Tensor | None = None):\n",
        "    \"\"\"\n",
        "    Reference implementation in PyTorch:\n",
        "      attn = softmax(Q @ K.T + mask) @ V\n",
        "    \"\"\"\n",
        "    # TODO: implement torch reference (use float32 accumulation if needed)\n",
        "    # raise NotImplementedError\n",
        "    assert Q.shape == K.shape == V.shape, \"This toy reference assumes Q,K,V are all [N, D]\"\n",
        "    N, D = Q.shape\n",
        "\n",
        "    # Use fp32 for scores/softmax stability, regardless of input dtype\n",
        "    Qf = Q.to(torch.float32)\n",
        "    Kf = K.to(torch.float32)\n",
        "    Vf = V.to(torch.float32)\n",
        "\n",
        "    scores = Qf @ Kf.transpose(0, 1)  # [N, N]\n",
        "\n",
        "    if mask is not None:\n",
        "        assert mask.shape == (N, N), f\"mask must be [N, N], got {mask.shape}\"\n",
        "        scores = scores + mask.to(torch.float32)\n",
        "\n",
        "    P = torch.softmax(scores, dim=-1)  # row-wise softmax\n",
        "    O = P @ Vf  # [N, D]\n",
        "\n",
        "    return O\n",
        "\n",
        "@torch.no_grad()\n",
        "def check_correctness(device=\"cuda\", dtype=torch.float16, N=256, D=64, use_mask=True):\n",
        "    torch.manual_seed(0)\n",
        "    Q = torch.randn((N, D), device=device, dtype=dtype)\n",
        "    K = torch.randn((N, D), device=device, dtype=dtype)\n",
        "    V = torch.randn((N, D), device=device, dtype=dtype)\n",
        "\n",
        "    mask = None\n",
        "    if use_mask:\n",
        "        # TODO: create a causal mask (or padding mask)\n",
        "        mask = _make_additive_causal_mask(N, device=device, dtype=torch.float32)\n",
        "\n",
        "    # TODO:\n",
        "    # - Run torch reference\n",
        "    # - Run triton naive attention\n",
        "    # - Compare max/mean error\n",
        "    # raise NotImplementedError\n",
        "    # Reference (PyTorch)\n",
        "    out_ref = naive_attention_torch(Q, K, V, mask=mask)\n",
        "\n",
        "    # Triton naive\n",
        "    out_tri = naive_attention_triton(Q, K, V, mask=mask)\n",
        "\n",
        "    # Compare (cast both to fp32 for fair error)\n",
        "    diff = (out_tri.to(torch.float32) - out_ref.to(torch.float32)).abs()\n",
        "    max_err = diff.max().item()\n",
        "    mean_err = diff.mean().item()\n",
        "    rmse = torch.sqrt((diff * diff).mean()).item()\n",
        "\n",
        "    print(f\"[check_correctness] N={N}, D={D}, dtype={dtype}, use_mask={use_mask}\")\n",
        "    print(f\"  max_abs_err : {max_err:.6e}\")\n",
        "    print(f\"  mean_abs_err: {mean_err:.6e}\")\n",
        "    print(f\"  rmse        : {rmse:.6e}\")\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def quick_bench(device=\"cuda\", dtype=torch.float16, N=1024, D=64, iters=50, warmup=10, use_mask=False):\n",
        "    \"\"\"\n",
        "    Simple benchmark harness (intentionally minimal).\n",
        "    \"\"\"\n",
        "    Q = torch.randn((N, D), device=device, dtype=dtype)\n",
        "    K = torch.randn((N, D), device=device, dtype=dtype)\n",
        "    V = torch.randn((N, D), device=device, dtype=dtype)\n",
        "\n",
        "    mask = None\n",
        "    if use_mask:\n",
        "        # TODO: create mask\n",
        "        mask = _make_additive_causal_mask(N, device=device, dtype=torch.float32)\n",
        "\n",
        "    # TODO:\n",
        "    # - Warmup runs\n",
        "    # - Time with CUDA events\n",
        "    # - Print ms/iter for torch vs triton\n",
        "    # raise NotImplementedError\n",
        "    torch.manual_seed(0)\n",
        "\n",
        "    Q = torch.randn((N, D), device=device, dtype=dtype)\n",
        "    K = torch.randn((N, D), device=device, dtype=dtype)\n",
        "    V = torch.randn((N, D), device=device, dtype=dtype)\n",
        "\n",
        "    mask = None\n",
        "    if use_mask:\n",
        "        # Additive causal mask: 0 or -inf\n",
        "        mask = _make_additive_causal_mask(N, device=device, dtype=torch.float32)\n",
        "\n",
        "    # ----------------------------\n",
        "    # Warmup\n",
        "    # ----------------------------\n",
        "    for _ in range(warmup):\n",
        "        naive_attention_triton(Q, K, V, mask=mask)\n",
        "        naive_attention_torch(Q, K, V, mask=mask)\n",
        "    torch.cuda.synchronize()\n",
        "\n",
        "    # ----------------------------\n",
        "    # Benchmark Triton\n",
        "    # ----------------------------\n",
        "    start = torch.cuda.Event(enable_timing=True)\n",
        "    end = torch.cuda.Event(enable_timing=True)\n",
        "\n",
        "    start.record()\n",
        "    for _ in range(iters):\n",
        "        naive_attention_triton(Q, K, V, mask=mask)\n",
        "    end.record()\n",
        "    torch.cuda.synchronize()\n",
        "\n",
        "    triton_ms = start.elapsed_time(end) / iters\n",
        "\n",
        "    # ----------------------------\n",
        "    # Benchmark Torch\n",
        "    # ----------------------------\n",
        "    start.record()\n",
        "    for _ in range(iters):\n",
        "        naive_attention_torch(Q, K, V, mask=mask)\n",
        "    end.record()\n",
        "    torch.cuda.synchronize()\n",
        "\n",
        "    torch_ms = start.elapsed_time(end) / iters\n",
        "\n",
        "    speedup = torch_ms / triton_ms\n",
        "\n",
        "    print(f\"\\n[quick_bench]\")\n",
        "    print(f\"N={N}, D={D}, dtype={dtype}, mask={use_mask}\")\n",
        "    print(f\"Triton: {triton_ms:.3f} ms\")\n",
        "    print(f\"Torch : {torch_ms:.3f} ms\")\n",
        "    print(f\"Speedup (Torch/Triton): {speedup:.2f}x\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # TODO: run correctness + small bench\n",
        "    check_correctness(N=128, D=64, use_mask=True)\n",
        "    quick_bench(N=1024, D=64, use_mask=False)\n",
        "    # pass\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCE6hjmjwJaz",
        "outputId": "89cc081f-7147-4219-8714-e828c1640a5b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[check_correctness] N=128, D=64, dtype=torch.float16, use_mask=True\n",
            "  max_abs_err : 7.545948e-04\n",
            "  mean_abs_err: 1.005516e-04\n",
            "  rmse        : 1.451281e-04\n",
            "\n",
            "[quick_bench]\n",
            "N=1024, D=64, dtype=torch.float16, mask=False\n",
            "Triton: 4.049 ms\n",
            "Torch : 0.144 ms\n",
            "Speedup (Torch/Triton): 0.04x\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "QCKUF3QM8pml",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54468f3d-d052-444c-d160-5d3e04e4b51d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "# Day 3 Results (Naive Triton vs Torch)\n",
            "\n",
            "| impl | N | D | cfg | ms | GFLOP/s | est_GB/s | speedup_vs_torch |\n",
            "|------|---|---|-----|----|---------|----------|------------------|\n",
            "| torch | 256 | 64 | - | 0.0944 | 177.81 | 6.95 | 1.00x |\n",
            "| naive_triton | 256 | 64 | BM=64,BN=64,BK=32,SB=256,w=4 | 1.0278 | 16.32 | 0.64 | 0.09x |\n",
            "| torch | 256 | 64 | - | 0.0904 | 185.62 | 7.25 | 1.00x |\n",
            "| naive_triton | 256 | 64 | BM=128,BN=64,BK=32,SB=256,w=4 | 1.0256 | 16.36 | 0.64 | 0.09x |\n",
            "| torch | 256 | 64 | - | 0.0884 | 189.74 | 7.41 | 1.00x |\n",
            "| naive_triton | 256 | 64 | BM=64,BN=128,BK=32,SB=512,w=8 | 1.0265 | 16.34 | 0.64 | 0.09x |\n",
            "| torch | 512 | 64 | - | 0.1027 | 653.30 | 22.97 | 1.00x |\n",
            "| naive_triton | 512 | 64 | BM=64,BN=64,BK=32,SB=256,w=4 | 1.5901 | 42.20 | 1.48 | 0.07x |\n",
            "| torch | 512 | 64 | - | 0.1031 | 650.90 | 22.88 | 1.00x |\n",
            "| naive_triton | 512 | 64 | BM=128,BN=64,BK=32,SB=256,w=4 | 1.5892 | 42.23 | 1.48 | 0.07x |\n",
            "| torch | 512 | 64 | - | 0.1036 | 647.97 | 22.78 | 1.00x |\n",
            "| naive_triton | 512 | 64 | BM=64,BN=128,BK=32,SB=512,w=8 | 1.5887 | 42.24 | 1.49 | 0.07x |\n",
            "| torch | 1024 | 64 | - | 0.2434 | 1102.96 | 36.62 | 1.00x |\n",
            "| naive_triton | 1024 | 64 | BM=64,BN=64,BK=32,SB=256,w=4 | 3.7526 | 71.53 | 2.38 | 0.04x |\n",
            "| torch | 1024 | 64 | - | 0.1334 | 2012.36 | 66.82 | 1.00x |\n",
            "| naive_triton | 1024 | 64 | BM=128,BN=64,BK=32,SB=256,w=4 | 3.5791 | 75.00 | 2.49 | 0.04x |\n",
            "| torch | 1024 | 64 | - | 0.1335 | 2010.31 | 66.75 | 1.00x |\n",
            "| naive_triton | 1024 | 64 | BM=64,BN=128,BK=32,SB=512,w=8 | 3.5751 | 75.08 | 2.49 | 0.04x |\n"
          ]
        }
      ],
      "source": [
        "# day3_profile_bottleneck_skeleton.py\n",
        "# ============================================================\n",
        "# Day 3 ‚Äî Profiling + Bottleneck Analysis (NO SOLUTION)\n",
        "#\n",
        "# Goal:\n",
        "#   Profile naive attention vs torch attention, identify bottlenecks.\n",
        "#\n",
        "# Tasks:\n",
        "#   - Nsight Compute metrics:\n",
        "#       * DRAM throughput\n",
        "#       * SM efficiency\n",
        "#       * Stall reasons\n",
        "#   - Decide bottleneck:\n",
        "#       * memory-bound?\n",
        "#       * reduction-bound?\n",
        "#   - Sweep:\n",
        "#       * different block sizes\n",
        "#       * different sequence lengths\n",
        "#\n",
        "# Outputs:\n",
        "#   - Markdown table comparing naive vs torch (printed)\n",
        "#   - Bottleneck analysis template (printed)\n",
        "#\n",
        "# Notes:\n",
        "#   - Plug in your Day2 implementations:\n",
        "#       naive_attention_triton(Q,K,V,mask,cfg)\n",
        "#       naive_attention_torch(Q,K,V,mask)\n",
        "# ============================================================\n",
        "\n",
        "from __future__ import annotations\n",
        "import json\n",
        "from dataclasses import dataclass, asdict\n",
        "from typing import Optional, Dict, Any, List, Tuple\n",
        "\n",
        "import torch\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# TODO: import your Day2 implementations\n",
        "# ============================================================\n",
        "def naive_attention_triton(Q, K, V, mask=None, cfg=None):\n",
        "    # TODO: call your Triton naive attention implementation\n",
        "    # raise NotImplementedError\n",
        "    # return naive_attention_torch(Q, K, V, mask=mask)\n",
        "    _assert_cuda(Q, \"Q\")\n",
        "    _assert_cuda(K, \"K\")\n",
        "    _assert_cuda(V, \"V\")\n",
        "    assert Q.shape == K.shape, \"Q and K must have shape [N, D]\"\n",
        "    assert Q.shape == V.shape, \"For this toy naive version, assume V has shape [N, D]\"\n",
        "    N, D = Q.shape\n",
        "\n",
        "    if mask is not None:\n",
        "        _assert_cuda(mask, \"mask\")\n",
        "        assert mask.shape == (N, N), \"mask must be [N, N] additive mask (0 / -inf)\"\n",
        "\n",
        "    # 1) Scores: S = Q @ K^T   -> [N, N] (often fp32)\n",
        "    S = qk_t_triton(Q, K)\n",
        "\n",
        "    # 2) Probabilities: P = softmax(S + mask)  -> [N, N]\n",
        "    P = softmax_triton(S, mask)\n",
        "\n",
        "    # 3) Output: O = P @ V     -> [N, D]\n",
        "    O = pv_triton(P, V)\n",
        "\n",
        "    return O\n",
        "\n",
        "\n",
        "\n",
        "def naive_attention_torch(Q, K, V, mask=None):\n",
        "    # TODO: call your PyTorch reference implementation\n",
        "    # raise NotImplementedError\n",
        "    # return naive_attention_torch(Q, K, V, mask=mask)\n",
        "    assert Q.shape == K.shape == V.shape, \"This toy reference assumes Q,K,V are all [N, D]\"\n",
        "    N, D = Q.shape\n",
        "\n",
        "    # Use fp32 for scores/softmax stability, regardless of input dtype\n",
        "    Qf = Q.to(torch.float32)\n",
        "    Kf = K.to(torch.float32)\n",
        "    Vf = V.to(torch.float32)\n",
        "\n",
        "    scores = Qf @ Kf.transpose(0, 1)  # [N, N]\n",
        "\n",
        "    if mask is not None:\n",
        "        assert mask.shape == (N, N), f\"mask must be [N, N], got {mask.shape}\"\n",
        "        scores = scores + mask.to(torch.float32)\n",
        "\n",
        "    P = torch.softmax(scores, dim=-1)  # row-wise softmax\n",
        "    O = P @ Vf  # [N, D]\n",
        "\n",
        "    return O\n",
        "\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Config definition for block size sweep\n",
        "# ============================================================\n",
        "@dataclass(frozen=True)\n",
        "class TritonNaiveCfg:\n",
        "    BLOCK_M: int\n",
        "    BLOCK_N: int\n",
        "    BLOCK_K: int\n",
        "    SOFTMAX_BLOCK: int\n",
        "    num_warps: int = 4\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Benchmark utilities\n",
        "# ============================================================\n",
        "def cuda_time_ms(fn, iters=30, warmup=10) -> float:\n",
        "    for _ in range(warmup):\n",
        "        fn()\n",
        "    torch.cuda.synchronize()\n",
        "\n",
        "    start = torch.cuda.Event(enable_timing=True)\n",
        "    end = torch.cuda.Event(enable_timing=True)\n",
        "\n",
        "    start.record()\n",
        "    for _ in range(iters):\n",
        "        fn()\n",
        "    end.record()\n",
        "    torch.cuda.synchronize()\n",
        "\n",
        "    return start.elapsed_time(end) / iters\n",
        "\n",
        "\n",
        "def gflops_qk_pv(N: int, D: int) -> float:\n",
        "    flops = 4.0 * N * N * D\n",
        "    return flops / 1e9\n",
        "\n",
        "\n",
        "def estimate_bytes(N: int, D: int, elem_bytes: int = 2) -> int:\n",
        "    # TODO: refine if using fp32 intermediate\n",
        "    qkv = 3 * N * D * elem_bytes\n",
        "    s_mat = 2 * N * N * elem_bytes\n",
        "    p_mat = 2 * N * N * elem_bytes\n",
        "    out = N * D * elem_bytes\n",
        "    return qkv + s_mat + p_mat + out\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Experiment execution\n",
        "# ============================================================\n",
        "@dataclass\n",
        "class ResultRow:\n",
        "    impl: str\n",
        "    N: int\n",
        "    D: int\n",
        "    cfg: Optional[Dict[str, Any]]\n",
        "    ms: float\n",
        "    gflops: float\n",
        "    est_gbs: float\n",
        "\n",
        "\n",
        "def run_case(N: int, D: int, cfg: TritonNaiveCfg):\n",
        "    device = \"cuda\"\n",
        "    dtype = torch.float16\n",
        "\n",
        "    Q = torch.randn((N, D), device=device, dtype=dtype)\n",
        "    K = torch.randn((N, D), device=device, dtype=dtype)\n",
        "    V = torch.randn((N, D), device=device, dtype=dtype)\n",
        "\n",
        "    # --- Torch baseline ---\n",
        "    def fn_torch():\n",
        "        return naive_attention_torch(Q, K, V, mask=None)\n",
        "\n",
        "    ms_torch = cuda_time_ms(fn_torch)\n",
        "    gflops = gflops_qk_pv(N, D)\n",
        "    bytes_est = estimate_bytes(N, D)\n",
        "\n",
        "    torch_row = ResultRow(\n",
        "        impl=\"torch\",\n",
        "        N=N,\n",
        "        D=D,\n",
        "        cfg=None,\n",
        "        ms=ms_torch,\n",
        "        gflops=gflops / (ms_torch / 1e3),\n",
        "        est_gbs=(bytes_est / (ms_torch / 1e3)) / 1e9,\n",
        "    )\n",
        "\n",
        "    # --- Triton naive ---\n",
        "    def fn_triton():\n",
        "        return naive_attention_triton(Q, K, V, mask=None, cfg=cfg)\n",
        "\n",
        "    ms_triton = cuda_time_ms(fn_triton)\n",
        "\n",
        "    triton_row = ResultRow(\n",
        "        impl=\"naive_triton\",\n",
        "        N=N,\n",
        "        D=D,\n",
        "        cfg=asdict(cfg),\n",
        "        ms=ms_triton,\n",
        "        gflops=gflops / (ms_triton / 1e3),\n",
        "        est_gbs=(bytes_est / (ms_triton / 1e3)) / 1e9,\n",
        "    )\n",
        "\n",
        "    return torch_row, triton_row\n",
        "\n",
        "\n",
        "def sweep(seq_lens: List[int], D: int, cfgs: List[TritonNaiveCfg]):\n",
        "    rows: List[ResultRow] = []\n",
        "    for N in seq_lens:\n",
        "        for cfg in cfgs:\n",
        "            torch_row, triton_row = run_case(N, D, cfg)\n",
        "            rows.append(torch_row)\n",
        "            rows.append(triton_row)\n",
        "    return rows\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Output formatting\n",
        "# ============================================================\n",
        "def print_markdown_table(rows: List[ResultRow]):\n",
        "    print(\"\\n# Day 3 Results (Naive Triton vs Torch)\\n\")\n",
        "    print(\"| impl | N | D | cfg | ms | GFLOP/s | est_GB/s | speedup_vs_torch |\")\n",
        "    print(\"|------|---|---|-----|----|---------|----------|------------------|\")\n",
        "\n",
        "    torch_map = {(r.N, r.D): r.ms for r in rows if r.impl == \"torch\"}\n",
        "\n",
        "    for r in rows:\n",
        "        base = torch_map.get((r.N, r.D), None)\n",
        "        speedup = base / r.ms if (base and r.impl != \"torch\") else 1.0\n",
        "\n",
        "        cfg_str = \"-\"\n",
        "        if r.cfg:\n",
        "            cfg_str = f\"BM={r.cfg['BLOCK_M']},BN={r.cfg['BLOCK_N']},BK={r.cfg['BLOCK_K']},SB={r.cfg['SOFTMAX_BLOCK']},w={r.cfg['num_warps']}\"\n",
        "\n",
        "        print(f\"| {r.impl} | {r.N} | {r.D} | {cfg_str} | \"\n",
        "              f\"{r.ms:.4f} | {r.gflops:.2f} | {r.est_gbs:.2f} | \"\n",
        "              f\"{speedup:.2f}x |\")\n",
        "\n",
        "\n",
        "def print_bottleneck():\n",
        "    print(\"\\n\\n# Bottleneck Analysis (Fill After Nsight Compute)\\n\")\n",
        "    print(\"## Nsight Compute Observations\")\n",
        "    print(\"- DRAM throughput (% peak): TODO\")\n",
        "    print(\"- SM throughput (% peak): TODO\")\n",
        "    print(\"- Dominant stall reasons:\")\n",
        "    print(\"  - long scoreboard: TODO\")\n",
        "    print(\"  - memory dependency: TODO\")\n",
        "    print(\"  - barrier: TODO\")\n",
        "    print(\"  - math pipe throttle: TODO\\n\")\n",
        "\n",
        "    print(\"## Bottleneck Classification\")\n",
        "    print(\"- [ ] Memory-bound\")\n",
        "    print(\"- [ ] Reduction-bound\")\n",
        "    print(\"- [ ] Compute-bound\\n\")\n",
        "\n",
        "    print(\"## Interpretation\")\n",
        "    print(\"- Naive attention materializes N√óN matrices.\")\n",
        "    print(\"- Softmax requires multiple passes (max/sum/normalize).\")\n",
        "    print(\"- Heavy DRAM traffic likely dominates performance.\\n\")\n",
        "\n",
        "    print(\"## Next Steps\")\n",
        "    print(\"- Tune block sizes.\")\n",
        "    print(\"- Increase arithmetic intensity.\")\n",
        "    print(\"- Consider fusion (FlashAttention).\\n\")\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Main\n",
        "# ============================================================\n",
        "def main():\n",
        "    if not torch.cuda.is_available():\n",
        "        raise RuntimeError(\"CUDA required.\")\n",
        "\n",
        "    seq_lens = [256, 512, 1024]  # TODO: extend if desired\n",
        "    D = 64\n",
        "\n",
        "    cfgs = [\n",
        "        TritonNaiveCfg(64, 64, 32, 256, 4),\n",
        "        TritonNaiveCfg(128, 64, 32, 256, 4),\n",
        "        TritonNaiveCfg(64, 128, 32, 512, 8),\n",
        "    ]\n",
        "\n",
        "    rows = sweep(seq_lens, D, cfgs)\n",
        "\n",
        "    print_markdown_table(rows)\n",
        "    # print_bottleneck()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "hmawQOy28pml",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "657436cb-6da1-41be-b8ee-68759796a6a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Memory Stats ===\n",
            "Contiguous KV: allocated=0.262 MB, used=0.262 MB\n",
            "Paged KV     : allocated=0.524 MB, used=0.262 MB, frag=50.00%\n",
            "====================\n",
            "\n",
            "\n",
            "=== Correctness Check ===\n",
            "T=1024, D=64, block_T=16, PB=128, M=1, dtype=torch.float16, use_mask=False\n",
            "max_abs_err  = 0.000000e+00\n",
            "mean_abs_err = 0.000000e+00\n",
            "[OK] Within tolerance.\n"
          ]
        }
      ],
      "source": [
        "# day4_paged_attention_toy_skeleton.py\n",
        "# ============================================================\n",
        "# Day 4 ‚Äî PageAttention (Toy) (NO SOLUTION)\n",
        "#\n",
        "# Goal:\n",
        "#   Understand vLLM-style KV cache paging by building a toy PageAttention in Triton.\n",
        "#\n",
        "# What you'll implement (toy scope):\n",
        "#   - Two KV cache modes:\n",
        "#       (1) Contiguous KV: K,V stored as [T, D] for each sequence (single sequence toy)\n",
        "#       (2) Paged KV: K,V stored in fixed-size blocks; a block table maps logical blocks to physical blocks\n",
        "#   - A toy attention computation that reads K,V via the selected layout:\n",
        "#       out = softmax(Q @ K^T + mask) @ V\n",
        "#\n",
        "# Tasks:\n",
        "#   - Study: contiguous KV vs paged KV\n",
        "#   - Design: KV block layout + block table\n",
        "#   - Implement: Triton PageAttention (toy)\n",
        "#   - Validate correctness vs torch reference\n",
        "#   - Memory usage stats (allocated bytes, fragmentation estimate)\n",
        "#\n",
        "# Notes:\n",
        "#   - This is a skeleton with TODOs only.\n",
        "#   - Keep it SIMPLE: single-head, single sequence, fp16 inputs, fp32 accum.\n",
        "#   - You can extend later to multi-head/batch.\n",
        "# ============================================================\n",
        "\n",
        "from __future__ import annotations\n",
        "import math\n",
        "from dataclasses import dataclass, asdict\n",
        "from typing import Optional, Dict, Any, Tuple\n",
        "\n",
        "import torch\n",
        "import triton\n",
        "import triton.language as tl\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Data structures\n",
        "# ============================================================\n",
        "@dataclass(frozen=True)\n",
        "class PageCfg:\n",
        "    # page/block size in tokens\n",
        "    BLOCK_T: int\n",
        "    # head dim\n",
        "    D: int\n",
        "    # number of physical blocks allocated in the KV pool\n",
        "    NUM_PHYS_BLOCKS: int\n",
        "\n",
        "    # toy kernel tiling knobs (optional)\n",
        "    BLOCK_M: int = 64      # query rows (here usually 1 query, but keep generic)\n",
        "    BLOCK_N: int = 128     # keys columns tile\n",
        "    num_warps: int = 4\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class MemStats:\n",
        "    mode: str\n",
        "    logical_T: int\n",
        "    D: int\n",
        "    block_T: int\n",
        "    num_logical_blocks: int\n",
        "    num_phys_blocks: int\n",
        "    kv_bytes_allocated: int\n",
        "    kv_bytes_used: int\n",
        "    fragmentation_bytes: int\n",
        "    fragmentation_ratio: float\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Helper: build additive causal mask (optional)\n",
        "# ============================================================\n",
        "def make_additive_causal_mask(T: int, device, dtype=torch.float32) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Returns [T, T] additive causal mask:\n",
        "      0 for j <= i\n",
        "      -inf for j > i\n",
        "    \"\"\"\n",
        "    # TODO: implement\n",
        "    # raise NotImplementedError\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Contiguous KV layout (toy)\n",
        "# ============================================================\n",
        "def alloc_contiguous_kv(T: int, D: int, device=\"cuda\", dtype=torch.float16) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "    \"\"\"\n",
        "    Allocate contiguous K,V as [T, D]\n",
        "    \"\"\"\n",
        "    K = torch.empty((T, D), device=device, dtype=dtype)\n",
        "    V = torch.empty((T, D), device=device, dtype=dtype)\n",
        "    return K, V\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Paged KV layout (toy)\n",
        "# ============================================================\n",
        "def alloc_paged_kv_pool(num_phys_blocks: int, block_T: int, D: int, device=\"cuda\", dtype=torch.float16):\n",
        "    \"\"\"\n",
        "    Allocate a KV pool with fixed blocks:\n",
        "      K_pool: [num_phys_blocks, block_T, D]\n",
        "      V_pool: [num_phys_blocks, block_T, D]\n",
        "    \"\"\"\n",
        "    K_pool = torch.empty((num_phys_blocks, block_T, D), device=device, dtype=dtype)\n",
        "    V_pool = torch.empty((num_phys_blocks, block_T, D), device=device, dtype=dtype)\n",
        "    return K_pool, V_pool\n",
        "\n",
        "\n",
        "def build_block_table(num_logical_blocks: int, num_phys_blocks: int, device=\"cuda\") -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Block table maps logical block idx -> physical block idx:\n",
        "      block_table[lb] = pb\n",
        "\n",
        "    For toy:\n",
        "      - you can map 0..L-1 to some subset of physical blocks\n",
        "      - support non-contiguous placement to mimic fragmentation avoidance\n",
        "\n",
        "    Returns:\n",
        "      block_table: [num_logical_blocks] int32\n",
        "    \"\"\"\n",
        "    # TODO: implement mapping strategy (e.g., random perm, or identity)\n",
        "    # raise NotImplementedError\n",
        "\n",
        "    assert num_logical_blocks <= num_phys_blocks, \"num_logical_blocks must be <= num_phys_blocks\"\n",
        "    assert num_logical_blocks >= 0, \"num_logical_blocks must be >= 0\"\n",
        "    assert num_phys_blocks > 0, \"num_phys_blocks must be > 0\"\n",
        "\n",
        "    if num_logical_blocks == 0:\n",
        "        return torch.empty((0,), device=device, dtype=torch.int32)\n",
        "\n",
        "    # random non-contiguous mapping (deterministic if you set torch.manual_seed outside)\n",
        "    perm = torch.randperm(num_phys_blocks, device=device, dtype=torch.int64)\n",
        "    block_table = perm[:num_logical_blocks].to(torch.int32)\n",
        "\n",
        "    return block_table\n",
        "\n",
        "\n",
        "def write_tokens_to_paged_kv(\n",
        "    K_tokens: torch.Tensor, V_tokens: torch.Tensor,\n",
        "    K_pool: torch.Tensor, V_pool: torch.Tensor,\n",
        "    block_table: torch.Tensor, block_T: int\n",
        "):\n",
        "    \"\"\"\n",
        "    Scatter logical tokens [T, D] into paged pools using block_table.\n",
        "    This simulates how vLLM stores KV into pages.\n",
        "\n",
        "    Inputs:\n",
        "      K_tokens, V_tokens: [T, D]\n",
        "      K_pool, V_pool: [PB, block_T, D]\n",
        "      block_table: [LB] (logical blocks)\n",
        "      block_T: tokens per block\n",
        "\n",
        "    TODO:\n",
        "      - For each logical token index t:\n",
        "          lb = t // block_T\n",
        "          off = t % block_T\n",
        "          pb = block_table[lb]\n",
        "          write into K_pool[pb, off, :]\n",
        "    \"\"\"\n",
        "    # TODO: implement scatter\n",
        "\n",
        "    # -----------------------------\n",
        "    # Step 1: Validate inputs (shapes / dtypes / devices)\n",
        "    # -----------------------------\n",
        "\n",
        "    assert isinstance(K_tokens, torch.Tensor) and isinstance(V_tokens, torch.Tensor)\n",
        "    assert isinstance(K_pool, torch.Tensor) and isinstance(V_pool, torch.Tensor)\n",
        "    assert isinstance(block_table, torch.Tensor)\n",
        "\n",
        "    # token tensors: [T, D]\n",
        "    assert K_tokens.ndim == 2, f\"K_tokens must be [T,D], got {K_tokens.shape}\"\n",
        "    assert V_tokens.ndim == 2, f\"V_tokens must be [T,D], got {V_tokens.shape}\"\n",
        "    assert K_tokens.shape == V_tokens.shape, f\"K_tokens and V_tokens must match, got {K_tokens.shape} vs {V_tokens.shape}\"\n",
        "    T, D = K_tokens.shape\n",
        "\n",
        "    # pool tensors: [PB, block_T, D]\n",
        "    assert K_pool.ndim == 3, f\"K_pool must be [PB,block_T,D], got {K_pool.shape}\"\n",
        "    assert V_pool.ndim == 3, f\"V_pool must be [PB,block_T,D], got {V_pool.shape}\"\n",
        "    assert K_pool.shape == V_pool.shape, f\"K_pool and V_pool must match, got {K_pool.shape} vs {V_pool.shape}\"\n",
        "    PB, BT, Dp = K_pool.shape\n",
        "\n",
        "    assert BT == block_T, f\"pool block_T={BT} must equal block_T arg={block_T}\"\n",
        "    assert Dp == D, f\"pool D={Dp} must equal tokens D={D}\"\n",
        "\n",
        "    # device consistency\n",
        "    dev = K_pool.device\n",
        "    assert K_tokens.device == dev, f\"K_tokens device {K_tokens.device} must match K_pool device {dev}\"\n",
        "    assert V_tokens.device == dev, f\"V_tokens device {V_tokens.device} must match K_pool device {dev}\"\n",
        "    assert V_pool.device == dev, f\"V_pool device {V_pool.device} must match K_pool device {dev}\"\n",
        "    assert block_table.device == dev, f\"block_table device {block_table.device} must match K_pool device {dev}\"\n",
        "\n",
        "    # dtype sanity (toy: usually fp16/bf16 for K/V pools)\n",
        "    assert K_tokens.dtype == K_pool.dtype, f\"K_tokens dtype {K_tokens.dtype} must match K_pool dtype {K_pool.dtype}\"\n",
        "    assert V_tokens.dtype == V_pool.dtype, f\"V_tokens dtype {V_tokens.dtype} must match V_pool dtype {V_pool.dtype}\"\n",
        "\n",
        "    # block_table: [LB] integer\n",
        "    assert block_table.ndim == 1, f\"block_table must be 1D [LB], got {block_table.shape}\"\n",
        "    assert block_table.dtype in (torch.int32, torch.int64), f\"block_table must be int32/int64, got {block_table.dtype}\"\n",
        "\n",
        "    # block_table must cover all logical blocks for T tokens\n",
        "    LB = (T + block_T - 1) // block_T\n",
        "    assert block_table.numel() >= LB, f\"block_table too short: need LB={LB}, got {block_table.numel()}\"\n",
        "\n",
        "    # pb range check (optional but strongly recommended)\n",
        "    # Only check the portion we will actually use (first LB entries)\n",
        "    bt_used = block_table[:LB].to(torch.int64)\n",
        "    assert int(bt_used.min().item()) >= 0, \"block_table contains negative physical block id\"\n",
        "    assert int(bt_used.max().item()) < PB, f\"block_table contains pb >= PB (PB={PB})\"\n",
        "\n",
        "    # Check uniqueness\n",
        "    unique_pb = torch.unique(bt_used)\n",
        "\n",
        "    assert unique_pb.numel() == bt_used.numel(), (\n",
        "        \"block_table contains duplicate physical block ids \"\n",
        "        \"(would cause KV overwrite)\"\n",
        "    )\n",
        "\n",
        "    # -----------------------------\n",
        "    # Step 2: Scatter write (pb scalar + write V_pool too)\n",
        "    # -----------------------------\n",
        "\n",
        "    for t in range(T):\n",
        "        lb = t // block_T\n",
        "        off = t % block_T\n",
        "\n",
        "        pb = int(block_table[lb].item())\n",
        "\n",
        "        K_pool[pb, off, :] = K_tokens[t, :]\n",
        "        V_pool[pb, off, :] = V_tokens[t, :]\n",
        "\n",
        "\n",
        "    # -----------------------------\n",
        "    # Step3: zero out unused slots in the last block (debug-friendly)\n",
        "    # -----------------------------\n",
        "    valid = T % block_T\n",
        "    if valid > 0:\n",
        "        lb_last = LB - 1  # last logical block\n",
        "        pb_last = int(block_table[lb_last].item())\n",
        "\n",
        "        pb_last = int(block_table[lb_last].item())\n",
        "        K_pool[pb_last, valid:, :].zero_()\n",
        "        V_pool[pb_last, valid:, :].zero_()\n",
        "\n",
        "    # raise NotImplementedError\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Memory stats\n",
        "# ============================================================\n",
        "def mem_stats_contiguous(T: int, D: int, dtype=torch.float16) -> MemStats:\n",
        "    elem = torch.tensor([], dtype=dtype).element_size()\n",
        "    used = 2 * T * D * elem  # K and V\n",
        "    return MemStats(\n",
        "        mode=\"contiguous\",\n",
        "        logical_T=T,\n",
        "        D=D,\n",
        "        block_T=0,\n",
        "        num_logical_blocks=0,\n",
        "        num_phys_blocks=0,\n",
        "        kv_bytes_allocated=used,\n",
        "        kv_bytes_used=used,\n",
        "        fragmentation_bytes=0,\n",
        "        fragmentation_ratio=0.0,\n",
        "    )\n",
        "\n",
        "\n",
        "def mem_stats_paged(T: int, cfg: PageCfg, dtype=torch.float16) -> MemStats:\n",
        "    elem = torch.tensor([], dtype=dtype).element_size()\n",
        "    block_T = cfg.BLOCK_T\n",
        "    LB = (T + block_T - 1) // block_T\n",
        "    allocated = 2 * cfg.NUM_PHYS_BLOCKS * block_T * cfg.D * elem\n",
        "    used = 2 * T * cfg.D * elem\n",
        "    frag = allocated - used\n",
        "    return MemStats(\n",
        "        mode=\"paged\",\n",
        "        logical_T=T,\n",
        "        D=cfg.D,\n",
        "        block_T=block_T,\n",
        "        num_logical_blocks=LB,\n",
        "        num_phys_blocks=cfg.NUM_PHYS_BLOCKS,\n",
        "        kv_bytes_allocated=allocated,\n",
        "        kv_bytes_used=used,\n",
        "        fragmentation_bytes=max(0, frag),\n",
        "        fragmentation_ratio=max(0.0, frag / max(1, allocated)),\n",
        "    )\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Triton: toy \"paged gather\" helper (kernel-side addressing)\n",
        "# ============================================================\n",
        "@triton.jit\n",
        "def paged_kv_gather_kernel(\n",
        "    # pointers\n",
        "    k_pool_ptr, v_pool_ptr,\n",
        "    block_table_ptr,\n",
        "    # output contiguous buffers for debugging (optional)\n",
        "    k_out_ptr, v_out_ptr,\n",
        "    # sizes\n",
        "    T: tl.constexpr, D: tl.constexpr,\n",
        "    BLOCK_T: tl.constexpr,\n",
        "    # strides (pool is [PB, BLOCK_T, D])\n",
        "    stride_kpb: tl.constexpr, stride_kpt: tl.constexpr, stride_kd: tl.constexpr,\n",
        "    stride_vpb: tl.constexpr, stride_vpt: tl.constexpr, stride_vd: tl.constexpr,\n",
        "    stride_out_t: tl.constexpr, stride_out_d: tl.constexpr,\n",
        "):\n",
        "    \"\"\"\n",
        "    OPTIONAL helper kernel:\n",
        "      Gather paged K/V into contiguous [T, D] buffers.\n",
        "    This is NOT how vLLM does it (they avoid materializing), but useful for debugging.\n",
        "\n",
        "    TODO:\n",
        "      - Map program id to a token block\n",
        "      - For each token t in the block:\n",
        "          lb = t // BLOCK_T\n",
        "          off = t % BLOCK_T\n",
        "          pb = block_table[lb]\n",
        "          load K_pool[pb, off, :]\n",
        "          store into k_out[t, :]\n",
        "      - Similarly for V\n",
        "    \"\"\"\n",
        "    # TODO: implement (optional)\n",
        "    # raise NotImplementedError\n",
        "\n",
        "    # ---- program id -> logical block id ----\n",
        "    pid = tl.program_id(axis=0)\n",
        "    t_idx = pid * BLOCK_T + tl.arange(0, BLOCK_T)\n",
        "    mask_t = t_idx < T\n",
        "    mask_td = mask_t[:, None]\n",
        "\n",
        "    # ---- logical block -> physical block ----\n",
        "    pb = tl.load(block_table_ptr + pid).to(tl.int64)\n",
        "\n",
        "    # ---- offsets within a block (tokens) and within a vector (D) ----\n",
        "    offs_t_in_block = tl.arange(0, BLOCK_T)\n",
        "    offs_d = tl.arange(0, D)\n",
        "\n",
        "    # ---- build pool pointers [BLOCK_T, D] ----\n",
        "    k_ptrs = k_pool_ptr + pb * stride_kpb + offs_t_in_block[:, None] * stride_kpt + offs_d[None, :] * stride_kd\n",
        "    v_ptrs = v_pool_ptr + pb * stride_vpb + offs_t_in_block[:, None] * stride_vpt + offs_d[None, :] * stride_vd\n",
        "\n",
        "    # ---- build output pointers [BLOCK_T, D] ----\n",
        "    k_out_ptrs = k_out_ptr + t_idx[:, None] * stride_out_t + offs_d[None, :] * stride_out_d\n",
        "    v_out_ptrs = v_out_ptr + t_idx[:, None] * stride_out_t + offs_d[None, :] * stride_out_d\n",
        "\n",
        "    # ---- load from pool and store to contiguous outputs ----\n",
        "    k = tl.load(k_ptrs, mask=mask_td, other=0.0)\n",
        "    v = tl.load(v_ptrs, mask=mask_td, other=0.0)\n",
        "\n",
        "    tl.store(k_out_ptrs, k, mask=mask_td)\n",
        "    tl.store(v_out_ptrs, v, mask=mask_td)\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Triton PageAttention (toy)\n",
        "# ============================================================\n",
        "@triton.jit\n",
        "def page_attention_kernel(\n",
        "    q_ptr,                    # [M, D]\n",
        "    k_pool_ptr, v_pool_ptr,   # [PB, BLOCK_T, D]\n",
        "    block_table_ptr,          # [LB]\n",
        "    mask_ptr,                 # [M, T] additive mask (optional, can be null/dummy if HAS_MASK=False)\n",
        "    out_ptr,                  # [M, D]\n",
        "    # sizes\n",
        "    M: tl.constexpr,\n",
        "    T: tl.constexpr,\n",
        "    D: tl.constexpr,\n",
        "    BLOCK_T: tl.constexpr,\n",
        "    # strides for Q [M, D]\n",
        "    stride_qm: tl.constexpr, stride_qd: tl.constexpr,\n",
        "    # strides for pool [PB, BLOCK_T, D]\n",
        "    stride_kpb: tl.constexpr, stride_kpt: tl.constexpr, stride_kd: tl.constexpr,\n",
        "    stride_vpb: tl.constexpr, stride_vpt: tl.constexpr, stride_vd: tl.constexpr,\n",
        "    # strides for mask [M, T]\n",
        "    stride_mm: tl.constexpr, stride_mt: tl.constexpr,\n",
        "    # strides for Out [M, D]\n",
        "    stride_om: tl.constexpr, stride_od: tl.constexpr,\n",
        "    # tiling\n",
        "    BLOCK_N: tl.constexpr,\n",
        "    HAS_MASK: tl.constexpr,\n",
        "):\n",
        "    \"\"\"\n",
        "    Toy paged attention:\n",
        "      out[m, :] = softmax( q[m,:] @ K[:T,:]^T + mask ) @ V[:T,:]\n",
        "\n",
        "    Constraints / simplifying assumptions:\n",
        "      - Single head\n",
        "      - Uses block_table to locate K/V blocks\n",
        "      - Does NOT attempt FlashAttention fusion tricks (this is day4, not day6)\n",
        "      - You may implement:\n",
        "          (A) full materialization of scores for toy correctness\n",
        "          or\n",
        "          (B) streaming softmax (more advanced, optional)\n",
        "    Skeleton expects TODOs only.\n",
        "\n",
        "    TODO:\n",
        "      1) Load q vector for row m\n",
        "      2) Iterate over key tiles t0:t0+BLOCK_N\n",
        "          - For each token t in tile:\n",
        "              lb = t // BLOCK_T\n",
        "              off = t % BLOCK_T\n",
        "              pb = block_table[lb]\n",
        "              load k = K_pool[pb, off, :]\n",
        "              compute score = dot(q, k)\n",
        "              apply mask if HAS_MASK\n",
        "          - softmax over T tokens (requires reduction across tiles)\n",
        "      3) Weighted sum over V similarly:\n",
        "          out = sum_j p_j * v_j\n",
        "\n",
        "    Because softmax needs a global normalization across all T,\n",
        "    you will likely need:\n",
        "      - a two-pass approach (scores -> softmax -> PV), OR\n",
        "      - an online softmax approach.\n",
        "\n",
        "    For this Day4 toy, pick the simplest correct approach.\n",
        "    \"\"\"\n",
        "    # TODO: implement\n",
        "    # raise NotImplementedError\n",
        "    m = tl.program_id(0)\n",
        "\n",
        "\n",
        "    # ---- load q[m, :] ----\n",
        "    d = tl.arange(0, D)\n",
        "    mask_d = d < D\n",
        "    q = tl.load(q_ptr + m * stride_qm + d * stride_qd, mask = mask_d, other = 0.0).to(tl.float32)\n",
        "    inv_sqrt_d = 1.0 / tl.sqrt(tl.full([], D, tl.float32))\n",
        "\n",
        "    # Pass 1: compute global max score for numerical stability\n",
        "    max_s = tl.full([], -float(\"inf\"), tl.float32)\n",
        "\n",
        "    for t0 in range(0, T, BLOCK_N):\n",
        "        t = t0 + tl.arange(0, BLOCK_N)               # [BN]\n",
        "        mask_t = t < T\n",
        "\n",
        "        #page address translation\n",
        "        lb = t // BLOCK_T                             # [BN]\n",
        "        off = t % BLOCK_T                             # [BN]\n",
        "\n",
        "        pb = tl.load(block_table_ptr + lb, mask=mask_t, other=0).to(tl.int64)  # [BN]\n",
        "\n",
        "\n",
        "        # load K tile: [BN, D]\n",
        "        k_ptrs = (k_pool_ptr + pb[:, None] * stride_kpb + off[:, None] * stride_kpt + d[None, :] * stride_kd)\n",
        "        k = tl.load(k_ptrs, mask=mask_t[:, None], other=0.0).to(tl.float32)\n",
        "\n",
        "        #score\n",
        "        s = tl.sum(k * q[None, :], axis=1) * inv_sqrt_d   # [BN]\n",
        "\n",
        "        if HAS_MASK:\n",
        "          mvals = tl.load(mask_ptr + m * stride_mm + t * stride_mt, mask=mask_t, other=-float(\"inf\")).to(tl.float32)\n",
        "          s = s + mvals\n",
        "\n",
        "        # invalid tokens -> -inf so they don't affect max\n",
        "        s = tl.where(mask_t, s, -float(\"inf\"))\n",
        "        max_s = tl.maximum(max_s, tl.max(s, axis=0))\n",
        "\n",
        "    # Pass 2: compute sumexp and accumulate PV\n",
        "    denom = tl.full([], 0.0, tl.float32)\n",
        "    out = tl.zeros([D], dtype=tl.float32)\n",
        "\n",
        "    for t0 in range(0, T, BLOCK_N):\n",
        "        t = t0 + tl.arange(0, BLOCK_N)\n",
        "        mask_t = t < T\n",
        "\n",
        "        lb = t // BLOCK_T\n",
        "        off = t % BLOCK_T\n",
        "\n",
        "        pb = tl.load(block_table_ptr + lb, mask=mask_t, other=0).to(tl.int64)\n",
        "\n",
        "        # load K tile: [BN, D]\n",
        "        k_ptrs = (k_pool_ptr + pb[:, None] * stride_kpb + off[:, None] * stride_kpt + d[None, :] * stride_kd)\n",
        "        k = tl.load(k_ptrs, mask=mask_t[:, None], other=0.0).to(tl.float32)\n",
        "\n",
        "        s = tl.sum(k * q[None, :], axis=1) * inv_sqrt_d  # [BN]\n",
        "\n",
        "        if HAS_MASK:\n",
        "            mvals = tl.load(mask_ptr + m * stride_mm + t * stride_mt, mask=mask_t, other=-float(\"inf\")).to(tl.float32)\n",
        "            s = s + mvals\n",
        "\n",
        "        s = tl.where(mask_t, s, -float(\"inf\"))\n",
        "\n",
        "        # exp(score - max)\n",
        "        w = tl.exp(s - max_s)                           # [BN]\n",
        "        w = tl.where(mask_t, w, 0.0)\n",
        "\n",
        "        denom += tl.sum(w, axis=0)\n",
        "\n",
        "        # load V: [BN, D]\n",
        "        v_ptrs = (v_pool_ptr + pb[:, None] * stride_vpb + off[:, None] * stride_vpt + d[None, :] * stride_vd)\n",
        "        v = tl.load(v_ptrs, mask=mask_t[:, None], other=0.0).to(tl.float32)\n",
        "\n",
        "        # out += sum_j w_j * v_j\n",
        "        out += tl.sum(v * w[:, None], axis=0)\n",
        "\n",
        "    # normalize\n",
        "    denom = tl.maximum(denom, 1e-9)\n",
        "    out = out / denom\n",
        "\n",
        "    # store\n",
        "    tl.store(out_ptr + m * stride_om + d * stride_od, out.to(tl.float16))\n",
        "\n",
        "# ============================================================\n",
        "# Torch references\n",
        "# ============================================================\n",
        "def attention_torch_contiguous(Q: torch.Tensor, K: torch.Tensor, V: torch.Tensor, mask: Optional[torch.Tensor] = None):\n",
        "    \"\"\"\n",
        "    Reference attention for contiguous KV:\n",
        "      out = softmax(Q @ K.T + mask) @ V\n",
        "    \"\"\"\n",
        "    # TODO: implement (use fp32 scores for stability)\n",
        "    # raise NotImplementedError\n",
        "    d = Q.shape[-1]\n",
        "\n",
        "\n",
        "    # fp32 compute for stability\n",
        "    scores = torch.matmul(Q.float(), K.float().transpose(-1, -2))\n",
        "    scores /= math.sqrt(d)\n",
        "\n",
        "    if mask is not None:\n",
        "        scores += mask.to(scores.dtype)\n",
        "\n",
        "    scores = scores.softmax(dim=-1)\n",
        "    out = torch.matmul(scores, V.float())\n",
        "\n",
        "    return out.to(Q.dtype)\n",
        "\n",
        "\n",
        "\n",
        "def attention_torch_from_paged(\n",
        "    Q: torch.Tensor,\n",
        "    K_pool: torch.Tensor, V_pool: torch.Tensor,\n",
        "    block_table: torch.Tensor, T: int, cfg: PageCfg,\n",
        "    mask: Optional[torch.Tensor] = None\n",
        "):\n",
        "    \"\"\"\n",
        "    Reference attention by first gathering paged KV into contiguous K,V (for correctness only).\n",
        "    Then run standard torch attention.\n",
        "    \"\"\"\n",
        "    # TODO:\n",
        "    # - gather K,V into [T,D] using block_table\n",
        "    # - call attention_torch_contiguous\n",
        "    # raise NotImplementedError\n",
        "\n",
        "\n",
        "    # Shapes (toy):\n",
        "    # Q:        [M, D]\n",
        "    # K_pool:   [PB, BLOCK_T, D]\n",
        "    # V_pool:   [PB, BLOCK_T, D]\n",
        "    # block_table: [LB] where LB = ceil(T / BLOCK_T)\n",
        "    # mask:     None or [M, T] additive mask\n",
        "\n",
        "    assert Q.ndim == 2, f\"Q must be [M,D], got {Q.shape}\"\n",
        "    assert K_pool.ndim == 3 and V_pool.ndim == 3, f\"K_pool/V_pool must be [PB,BLOCK_T,D]\"\n",
        "    assert K_pool.shape == V_pool.shape, \"K_pool and V_pool must have same shape\"\n",
        "    PB, BLOCK_T, D = K_pool.shape\n",
        "\n",
        "    assert D == cfg.D, f\"Pool D={D} must match cfg.D={cfg.D}\"\n",
        "    assert BLOCK_T == cfg.BLOCK_T, f\"Pool BLOCK_T={BLOCK_T} must match cfg.BLOCK_T={cfg.BLOCK_T}\"\n",
        "    assert Q.shape[1] == D, f\"Q D={Q.shape[1]} must match pool D={D}\"\n",
        "    assert 0 < T <= cfg.BLOCK_T * K_pool.shape[0] * 10_000, \"T looks unreasonable for given pool (sanity check)\"\n",
        "\n",
        "\n",
        "    # block_table length must cover all logical blocks needed for T tokens\n",
        "    LB = (T + BLOCK_T - 1) // BLOCK_T\n",
        "    assert block_table.ndim == 1, f\"block_table must be 1D, got {block_table.shape}\"\n",
        "    assert block_table.numel() >= LB, f\"block_table too short: need {LB}, got {block_table.numel()}\"\n",
        "    assert block_table.dtype in (torch.int32, torch.int64)\n",
        "\n",
        "    # Build logical token indices [0..T-1]\n",
        "    device = Q.device\n",
        "    t_idx = torch.arange(T, device=device, dtype=torch.int64)          # [T]\n",
        "    lb = t_idx // BLOCK_T                                              # [T]\n",
        "    off = t_idx % BLOCK_T                                              # [T]\n",
        "    pb = block_table[lb].to(torch.int64)                               # [T]\n",
        "\n",
        "\n",
        "    # Gather K,V into contiguous [T,D]\n",
        "    # Advanced indexing: K_pool[pb, off] -> [T,D]\n",
        "    K_contig = K_pool[pb, off, :]                                      # [T,D]\n",
        "    V_contig = V_pool[pb, off, :]                                      # [T,D]\n",
        "\n",
        "\n",
        "    return attention_torch_contiguous(Q, K_contig, V_contig, mask=mask)\n",
        "\n",
        "# ============================================================\n",
        "# Driver: build toy data, run correctness checks\n",
        "# ============================================================\n",
        "@torch.no_grad()\n",
        "def check_correctness(\n",
        "    T: int = 1024,\n",
        "    D: int = 64,\n",
        "    block_T: int = 16,\n",
        "    num_phys_blocks: int = 128,\n",
        "    M: int = 1,\n",
        "    dtype=torch.float16,\n",
        "    use_mask: bool = False,\n",
        "):\n",
        "    device = \"cuda\"\n",
        "    torch.manual_seed(0)\n",
        "\n",
        "    cfg = PageCfg(BLOCK_T=block_T, D=D, NUM_PHYS_BLOCKS=num_phys_blocks)\n",
        "\n",
        "    # Create a toy query (M queries)\n",
        "    Q = torch.randn((M, D), device=device, dtype=dtype)\n",
        "\n",
        "    # Create logical tokens for KV (as if appended over time)\n",
        "    K_tokens = torch.randn((T, D), device=device, dtype=dtype)\n",
        "    V_tokens = torch.randn((T, D), device=device, dtype=dtype)\n",
        "\n",
        "    # --- Contiguous baseline ---\n",
        "    K_contig, V_contig = alloc_contiguous_kv(T, D, device=device, dtype=dtype)\n",
        "    K_contig.copy_(K_tokens)\n",
        "    V_contig.copy_(V_tokens)\n",
        "\n",
        "    mask = None\n",
        "    if use_mask:\n",
        "        # TODO: define mask shape; for toy use [M, T] or [M, T] additive\n",
        "        # or full [M, T] if you compute scores row-wise.\n",
        "        # mask = ...\n",
        "        # raise NotImplementedError(\"TODO: mask construction\")\n",
        "        keep = T // 2\n",
        "        mask = torch.zeros((M, T), device=device, dtype=torch.float32)\n",
        "        mask[:, keep:] = float(\"-inf\")\n",
        "\n",
        "    # TODO: torch contiguous reference\n",
        "    # out_ref = attention_torch_contiguous(Q, K_contig, V_contig, mask=mask)\n",
        "    out_ref = attention_torch_contiguous(Q, K_contig, V_contig, mask=mask)\n",
        "\n",
        "    # --- Paged layout ---\n",
        "    K_pool, V_pool = alloc_paged_kv_pool(num_phys_blocks, block_T, D, device=device, dtype=dtype)\n",
        "    LB = (T + block_T - 1) // block_T\n",
        "    block_table = build_block_table(LB, num_phys_blocks, device=device)\n",
        "\n",
        "    write_tokens_to_paged_kv(K_tokens, V_tokens, K_pool, V_pool, block_table, block_T)\n",
        "\n",
        "    # TODO: Triton paged attention\n",
        "    # out_paged = page_attention_triton(Q, K_pool, V_pool, block_table, T, cfg, mask=mask)\n",
        "    out_paged = page_attention_triton(Q, K_pool, V_pool, block_table, T, cfg, mask=mask)\n",
        "\n",
        "    # TODO: compare out_paged with out_ref\n",
        "    # max_err = (out_paged - out_ref).abs().max().item()\n",
        "    # mean_err = (out_paged - out_ref).abs().mean().item()\n",
        "    # print(...)\n",
        "    # raise NotImplementedError\n",
        "    diff = (out_paged - out_ref).float()\n",
        "    max_err = diff.abs().max().item()\n",
        "    mean_err = diff.abs().mean().item()\n",
        "\n",
        "    print(\"\\n=== Correctness Check ===\")\n",
        "    print(f\"T={T}, D={D}, block_T={block_T}, PB={num_phys_blocks}, M={M}, dtype={dtype}, use_mask={use_mask}\")\n",
        "    print(f\"max_abs_err  = {max_err:.6e}\")\n",
        "    print(f\"mean_abs_err = {mean_err:.6e}\")\n",
        "\n",
        "    # Simple tolerance guidance (toy fp16): adjust if needed\n",
        "    tol = 5e-2 if dtype in (torch.float16, torch.bfloat16) else 1e-4\n",
        "    if max_err > tol:\n",
        "        print(f\"[WARN] max_err {max_err:.3e} > tol {tol:.3e} (check paging addr / mask / numerics)\")\n",
        "    else:\n",
        "        print(\"[OK] Within tolerance.\")\n",
        "\n",
        "    return {\n",
        "        \"max_abs_err\": max_err,\n",
        "        \"mean_abs_err\": mean_err,\n",
        "        \"out_ref\": out_ref,\n",
        "        \"out_paged\": out_paged,\n",
        "        \"mask\": mask,\n",
        "        \"block_table\": block_table,\n",
        "    }\n",
        "\n",
        "\n",
        "def page_attention_triton(\n",
        "    Q: torch.Tensor,\n",
        "    K_pool: torch.Tensor,\n",
        "    V_pool: torch.Tensor,\n",
        "    block_table: torch.Tensor,\n",
        "    T: int,\n",
        "    cfg: PageCfg,\n",
        "    mask: Optional[torch.Tensor] = None,\n",
        "    BLOCK_N: int = 128,\n",
        "    num_warps: int = 4,\n",
        ") -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Launcher for page_attention_kernel.\n",
        "    Q: [M, D]\n",
        "    K_pool/V_pool: [PB, BLOCK_T, D]\n",
        "    block_table: [LB]\n",
        "    Returns:\n",
        "      out: [M, D]\n",
        "    \"\"\"\n",
        "    # TODO:\n",
        "    # - Validate shapes/dtypes\n",
        "    # - Allocate out\n",
        "    # - Define grid (e.g., one program per query row m)\n",
        "    # - Pass strides and constexpr args\n",
        "    # - HAS_MASK toggle\n",
        "    # raise NotImplementedError\n",
        "    assert Q.ndim == 2\n",
        "    M, D = Q.shape\n",
        "    assert K_pool.ndim == 3 and V_pool.ndim == 3\n",
        "    PB, BT, Dp = K_pool.shape\n",
        "    assert (PB, BT, Dp) == V_pool.shape\n",
        "    assert BT == cfg.BLOCK_T and Dp == D\n",
        "    LB = (T + cfg.BLOCK_T - 1) // cfg.BLOCK_T\n",
        "    assert block_table.ndim == 1 and block_table.numel() >= LB\n",
        "    assert block_table.dtype in (torch.int32, torch.int64)\n",
        "\n",
        "    out = torch.empty((M, D), device=Q.device, dtype=Q.dtype)\n",
        "\n",
        "    HAS_MASK = mask is not None\n",
        "    if HAS_MASK:\n",
        "        assert mask.shape == (M, T), f\"mask must be [M,T], got {mask.shape}\"\n",
        "        # mask can be fp16/fp32; kernel reads as fp32\n",
        "        mask_ptr = mask\n",
        "        stride_mm, stride_mt = mask.stride()\n",
        "    else:\n",
        "        # dummy tensor (won't be read when HAS_MASK=False)\n",
        "        mask_ptr = out  # any valid pointer on device\n",
        "        stride_mm, stride_mt = 0, 0\n",
        "\n",
        "    grid = (M,)\n",
        "    page_attention_kernel[grid](\n",
        "        Q, K_pool, V_pool, block_table, mask_ptr, out,\n",
        "        M=M, T=T, D=D, BLOCK_T=cfg.BLOCK_T,\n",
        "        stride_qm=Q.stride(0), stride_qd=Q.stride(1),\n",
        "        stride_kpb=K_pool.stride(0), stride_kpt=K_pool.stride(1), stride_kd=K_pool.stride(2),\n",
        "        stride_vpb=V_pool.stride(0), stride_vpt=V_pool.stride(1), stride_vd=V_pool.stride(2),\n",
        "        stride_mm=stride_mm, stride_mt=stride_mt,\n",
        "        stride_om=out.stride(0), stride_od=out.stride(1),\n",
        "        BLOCK_N=BLOCK_N,\n",
        "        HAS_MASK=HAS_MASK,\n",
        "        num_warps=num_warps,\n",
        "    )\n",
        "\n",
        "    return out\n",
        "\n",
        "# ============================================================\n",
        "# Memory statistics printing\n",
        "# ============================================================\n",
        "def print_mem_stats(T: int, D: int, cfg: PageCfg, dtype=torch.float16):\n",
        "    c = mem_stats_contiguous(T, D, dtype=dtype)\n",
        "    p = mem_stats_paged(T, cfg, dtype=dtype)\n",
        "\n",
        "    print(\"\\n=== Memory Stats ===\")\n",
        "    print(f\"Contiguous KV: allocated={c.kv_bytes_allocated/1e6:.3f} MB, used={c.kv_bytes_used/1e6:.3f} MB\")\n",
        "    print(f\"Paged KV     : allocated={p.kv_bytes_allocated/1e6:.3f} MB, used={p.kv_bytes_used/1e6:.3f} MB, \"\n",
        "          f\"frag={p.fragmentation_ratio*100:.2f}%\")\n",
        "    print(\"====================\\n\")\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Main\n",
        "# ============================================================\n",
        "def main():\n",
        "    if not torch.cuda.is_available():\n",
        "        raise RuntimeError(\"CUDA required.\")\n",
        "\n",
        "    # TODO: adjust toy parameters\n",
        "    T = 1024\n",
        "    D = 64\n",
        "    block_T = 16\n",
        "    num_phys_blocks = 128\n",
        "    M = 1\n",
        "\n",
        "    cfg = PageCfg(BLOCK_T=block_T, D=D, NUM_PHYS_BLOCKS=num_phys_blocks)\n",
        "    print_mem_stats(T, D, cfg, dtype=torch.float16)\n",
        "\n",
        "    # TODO: run correctness\n",
        "    check_correctness(T=T, D=D, block_T=block_T, num_phys_blocks=num_phys_blocks, M=M, use_mask=False)\n",
        "    # raise NotImplementedError(\"TODO: wire up correctness once kernels are implemented\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "MN2WzkMz8pmm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b426413-877f-43c4-aee1-05bf4830d10b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "N=256, D=64, dtype=torch.float16, use_mask=False, causal=True\n",
            "max_abs_err = 2.441e-04\n",
            "mean_abs_err = 4.479e-08\n",
            "| N | Impl | ms | speedup_vs_naive |\n",
            "|---|------|----|------------------|\n",
            "| 256 | naive | 1.0282 | 1.00x |\n",
            "| 256 | flash | 0.2426 | 4.24x |\n",
            "| 512 | naive | 1.7125 | 1.00x |\n",
            "| 512 | flash | 0.4714 | 3.63x |\n",
            "| 1024 | naive | 3.7537 | 1.00x |\n",
            "| 1024 | flash | 0.5541 | 6.77x |\n",
            "| 1024 | naive | 3.5619 | 1.00x |\n",
            "| 1024 | flash | 0.4618 | 7.71x |\n"
          ]
        }
      ],
      "source": [
        "# day6_flashattention_mini_skeleton.py\n",
        "# ============================================================\n",
        "# Day 6 ‚Äî Triton FlashAttention (Mini) (NO SOLUTION)\n",
        "#\n",
        "# Goal:\n",
        "#   Implement a mini FlashAttention-style kernel in Triton:\n",
        "#     - tiled QK^T\n",
        "#     - online softmax (streaming max/sum)\n",
        "#     - fuse V multiplication\n",
        "#     - single kernel end-to-end\n",
        "#   Then:\n",
        "#     - validate correctness vs PyTorch\n",
        "#     - compare performance vs naive attention (Day2)\n",
        "#\n",
        "# Scope (toy but realistic):\n",
        "#   - Single head (extend later)\n",
        "#   - One batch (extend later)\n",
        "#   - Q,K,V: [N, D] (N = seq length, D = head dim)\n",
        "#   - Output O: [N, D]\n",
        "#   - Optional causal mask (recommended)\n",
        "#   - Inputs fp16/bf16, accumulate fp32\n",
        "#\n",
        "# Notes:\n",
        "#   - This is a skeleton with TODOs only (no solution).\n",
        "#   - You will need to choose tiling sizes that fit SRAM (shared memory/registers).\n",
        "# ============================================================\n",
        "\n",
        "from __future__ import annotations\n",
        "import math\n",
        "from dataclasses import dataclass, asdict\n",
        "from typing import Optional, Dict, Any, Tuple, List\n",
        "\n",
        "import torch\n",
        "import triton\n",
        "import triton.language as tl\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# TODO: import your Day2 naive attention for comparison\n",
        "# ============================================================\n",
        "def naive_attention_triton(Q, K, V, mask=None, cfg=None):\n",
        "    # TODO: import and call your Day2 implementation\n",
        "    _assert_cuda(Q, \"Q\")\n",
        "    _assert_cuda(K, \"K\")\n",
        "    _assert_cuda(V, \"V\")\n",
        "    assert Q.shape == K.shape, \"Q and K must have shape [N, D]\"\n",
        "    assert Q.shape == V.shape, \"For this toy naive version, assume V has shape [N, D]\"\n",
        "    N, D = Q.shape\n",
        "\n",
        "    if mask is not None:\n",
        "        _assert_cuda(mask, \"mask\")\n",
        "        assert mask.shape == (N, N), \"mask must be [N, N] additive mask (0 / -inf)\"\n",
        "\n",
        "    # 1) Scores: S = Q @ K^T   -> [N, N] (often fp32)\n",
        "    S = qk_t_triton(Q, K)\n",
        "\n",
        "    # 2) Probabilities: P = softmax(S + mask)  -> [N, N]\n",
        "    P = softmax_triton(S, mask)\n",
        "\n",
        "    # 3) Output: O = P @ V     -> [N, D]\n",
        "    O = pv_triton(P, V)\n",
        "\n",
        "    return O\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Config\n",
        "# ============================================================\n",
        "@dataclass(frozen=True)\n",
        "class FlashCfg:\n",
        "    BLOCK_M: int     # rows of Q processed per program\n",
        "    BLOCK_N: int     # cols of K/V per step (streaming over N)\n",
        "    BLOCK_D: int     # head dim tile (usually == D, but keep generic)\n",
        "    num_warps: int = 4\n",
        "    num_stages: int = 2  # optional pipelining\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Mask helper (optional)\n",
        "# ============================================================\n",
        "def make_additive_causal_mask(N: int, device=\"cuda\", dtype=torch.float32) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Returns additive causal mask [N, N]:\n",
        "      0 for j <= i, -inf for j > i\n",
        "    Used as: scores = scores + mask\n",
        "    \"\"\"\n",
        "    # TODO: implement\n",
        "    # raise NotImplementedError\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# FlashAttention mini kernel (single kernel)\n",
        "# ============================================================\n",
        "@triton.jit\n",
        "def flashattn_mini_kernel(\n",
        "    q_ptr, k_ptr, v_ptr, o_ptr,\n",
        "    # optional mask pointer (additive), can be None by HAS_MASK flag\n",
        "    mask_ptr,\n",
        "    N: tl.constexpr, D: tl.constexpr,\n",
        "    stride_qn: tl.constexpr, stride_qd: tl.constexpr,\n",
        "    stride_kn: tl.constexpr, stride_kd: tl.constexpr,\n",
        "    stride_vn: tl.constexpr, stride_vd: tl.constexpr,\n",
        "    stride_on: tl.constexpr, stride_od: tl.constexpr,\n",
        "    # mask strides (if used): mask is [N, N] additive\n",
        "    stride_mn: tl.constexpr, stride_mm: tl.constexpr,\n",
        "    # tiling\n",
        "    BLOCK_M: tl.constexpr,\n",
        "    BLOCK_N: tl.constexpr,\n",
        "    BLOCK_D: tl.constexpr,\n",
        "    HAS_MASK: tl.constexpr,\n",
        "    IS_CAUSAL: tl.constexpr,\n",
        "    # scale (typically 1/sqrt(D))\n",
        "    SCALE: tl.constexpr,\n",
        "):\n",
        "    \"\"\"\n",
        "    Compute O = softmax(QK^T + mask) V using tiling + online softmax, fused with V.\n",
        "\n",
        "    Structure (conceptual):\n",
        "      For each block of queries (m tile):\n",
        "        - initialize:\n",
        "            m_i = -inf         # running max per query row\n",
        "            l_i = 0            # running sum(exp(scores - m_i))\n",
        "            acc = 0            # running output accumulator (fp32)\n",
        "        - for n_tile over keys/values:\n",
        "            scores = q_tile @ k_tile^T * SCALE + mask_tile\n",
        "            # online softmax update:\n",
        "            m_new = max(m_i, rowmax(scores))\n",
        "            alpha = exp(m_i - m_new)\n",
        "            p = exp(scores - m_new)\n",
        "            l_new = l_i * alpha + rowsum(p)\n",
        "            acc = acc * alpha[:,None] + p @ v_tile\n",
        "            m_i = m_new\n",
        "            l_i = l_new\n",
        "        - normalize:\n",
        "            out = acc / l_i[:,None]\n",
        "        - store out\n",
        "\n",
        "    TODOs:\n",
        "      - Map program_id to query block start\n",
        "      - Load Q tile [BLOCK_M, D] (or [BLOCK_M, BLOCK_D] with loop if needed)\n",
        "      - Loop over K/V tiles along N:\n",
        "          * Load K tile [BLOCK_N, D]\n",
        "          * Compute score tile [BLOCK_M, BLOCK_N] in fp32\n",
        "          * Apply causal masking if IS_CAUSAL (score for j>i = -inf)\n",
        "          * Apply additive mask if HAS_MASK (mask_ptr)\n",
        "          * Update online softmax stats (m_i, l_i)\n",
        "          * Fuse V multiplication: acc += p @ V_tile\n",
        "      - Final normalize acc by l_i\n",
        "      - Store O tile\n",
        "    \"\"\"\n",
        "    # TODO: implement\n",
        "    # raise NotImplementedError\n",
        "    #----------------Determine which query rows this block owns-----------------\n",
        "    pid = tl.program_id(axis=0)\n",
        "    m_start = pid * BLOCK_M\n",
        "\n",
        "    row = m_start + tl.arange(0, BLOCK_M)\n",
        "    row_mask = row < N\n",
        "    d = tl.arange(0, D) #[D]\n",
        "    d_mask   = d < D\n",
        "    q_mask   = row_mask[:, None] & d_mask[None, :]\n",
        "\n",
        "    #----------------Load a tile of Q-----------------\n",
        "    d = tl.arange(0, D)                      # [D]\n",
        "    q_ptrs = q_ptr + row[:, None] * stride_qn + d[None, :] * stride_qd\n",
        "    q = tl.load(q_ptrs, mask=q_mask, other=0.0)# [BM, D]\n",
        "\n",
        "    #----------------Initialize online softmax state-----------------\n",
        "    m = tl.full([BLOCK_M], -float(\"inf\"), tl.float32)\n",
        "    l = tl.zeros([BLOCK_M], tl.float32)\n",
        "    acc = tl.zeros([BLOCK_M, D], tl.float32)\n",
        "\n",
        "    #----------------Main Loop: Iterate over K/V tiles-----------------\n",
        "    for n_start in range(0, N, BLOCK_N):\n",
        "          # indices of K/V rows for this tile\n",
        "          col = n_start + tl.arange(0, BLOCK_N)# [BN]\n",
        "          col_mask = col < N\n",
        "\n",
        "          # load K tile [BLOCK_N, D]\n",
        "          k_ptrs = k_ptr + col[:, None] * stride_kn + d[None, :] * stride_kd  # [BN, D]\n",
        "          k_mask = col_mask[:, None] & d_mask[None, :]\n",
        "          k_tile = tl.load(k_ptrs, mask=k_mask, other=0.0)\n",
        "\n",
        "          # load V tile [BLOCK_N, D]\n",
        "          v_ptrs = v_ptr + col[:, None] * stride_vn + d[None, :] * stride_vd  # [BN, D]\n",
        "          v_mask = col_mask[:, None] & d_mask[None, :]\n",
        "          v_tile = tl.load(v_ptrs, mask=v_mask, other=0.0)\n",
        "\n",
        "          # compute score tile [BLOCK_M, BLOCK_N]\n",
        "          scores = tl.dot(q, tl.trans(k_tile)) * SCALE\n",
        "\n",
        "          if IS_CAUSAL:\n",
        "              # apply causal masking if IS_CAUSAL (score for j>i = -inf)\n",
        "              row_mask = row < N              # [BLOCK_M]\n",
        "              col_mask = col < N              # [BLOCK_N]\n",
        "\n",
        "              in_bounds = row_mask[:, None] & col_mask[None, :]  # [BLOCK_M, BLOCK_N]\n",
        "              causal_keep = col[None, :] <= row[:, None]         # [BLOCK_M, BLOCK_N]\n",
        "\n",
        "              keep = in_bounds & causal_keep\n",
        "              scores = tl.where(keep, scores, -float(\"inf\"))\n",
        "\n",
        "          if HAS_MASK:\n",
        "              # apply additive mask if HAS_MASK (mask_ptr)\n",
        "              mask_ptrs = mask_ptr + row[:, None] * stride_mn + col[None, :] * stride_mm\n",
        "              mask_load_mask = (row < N)[:, None] & (col < N)[None, :]\n",
        "              mask_tile = tl.load(mask_ptrs, mask=mask_load_mask, other=0.0).to(tl.float32)\n",
        "              scores = scores + mask_tile\n",
        "\n",
        "          # Online Softmax Update\n",
        "          # 1) row-wise max on this tile\n",
        "          s_max = tl.max(scores, axis=1)# [BLOCK_M]\n",
        "\n",
        "          # 2) new running max per row\n",
        "          m_new = tl.maximum(m, s_max)# [BLOCK_M]\n",
        "\n",
        "          # 3) rescale factor to bring old accumulators into the new max \"gauge\"\n",
        "          alpha = tl.exp(m - m_new)# [BLOCK_M]\n",
        "\n",
        "          # 4) exponentiate current tile scores using the new max (broadcast m_new across columns)\n",
        "          p = tl.exp(scores - m_new[:, None]) # [BLOCK_M, BLOCK_N]\n",
        "\n",
        "          # 5) update running sum per row\n",
        "          l_new = l * alpha + tl.sum(p, axis=1)        # [BLOCK_M]\n",
        "\n",
        "          # 6) update output accumulator (fused P @ V)\n",
        "          #    p is fp32; accumulate in fp32 for stability\n",
        "          acc = acc * alpha[:, None] + tl.dot(p, v_tile.to(tl.float32)) # [BLOCK_M, D]\n",
        "\n",
        "          # 7) commit\n",
        "          m = m_new\n",
        "          l = l_new\n",
        "\n",
        "\n",
        "    out = acc / l[:, None]   # [BLOCK_M, D]\n",
        "    d = tl.arange(0, D)  # [D]\n",
        "    o_ptrs = o_ptr + row[:, None] * stride_on + d[None, :] * stride_od   # [BLOCK_M, D]\n",
        "    row_mask = row < N\n",
        "    o_mask = row_mask[:, None]   # [BLOCK_M, 1] broadcast to [BLOCK_M, D]\n",
        "    tl.store(o_ptrs, out.to(tl.float16), mask=o_mask)\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Launcher\n",
        "# ============================================================\n",
        "def _assert_2d(x: torch.Tensor, name: str) -> None:\n",
        "    \"\"\"Assert tensor is 2D [N, D].\"\"\"\n",
        "    if not isinstance(x, torch.Tensor):\n",
        "        raise TypeError(f\"{name} must be a torch.Tensor, got {type(x)}\")\n",
        "    if x.ndim != 2:\n",
        "        raise ValueError(f\"{name} must be 2D [N, D], got shape {tuple(x.shape)}\")\n",
        "\n",
        "\n",
        "def _assert_cuda_contig(x: torch.Tensor, name: str) -> None:\n",
        "    \"\"\"Assert tensor is on CUDA and contiguous.\"\"\"\n",
        "    if not x.is_cuda:\n",
        "        raise ValueError(f\"{name} must be on CUDA, got {x.device}\")\n",
        "    if not x.is_contiguous():\n",
        "        raise ValueError(f\"{name} must be contiguous, got strides {x.stride()} and shape {tuple(x.shape)}\")\n",
        "def flashattn_mini_triton(\n",
        "    Q: torch.Tensor, K: torch.Tensor, V: torch.Tensor,\n",
        "    mask: Optional[torch.Tensor] = None,\n",
        "    causal: bool = False,\n",
        "    cfg: FlashCfg = FlashCfg(BLOCK_M=32, BLOCK_N=64, BLOCK_D=64, num_warps=4),\n",
        ") -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Q,K,V: [N, D] contiguous CUDA tensors\n",
        "    mask: additive [N, N] or None\n",
        "    causal: if True, apply causal mask internally\n",
        "    \"\"\"\n",
        "\n",
        "    # -----------------------------\n",
        "    # Validate Q/K/V\n",
        "    # -----------------------------\n",
        "    _assert_2d(Q, \"Q\")\n",
        "    _assert_2d(K, \"K\")\n",
        "    _assert_2d(V, \"V\")\n",
        "\n",
        "    _assert_cuda_contig(Q, \"Q\")\n",
        "    _assert_cuda_contig(K, \"K\")\n",
        "    _assert_cuda_contig(V, \"V\")\n",
        "\n",
        "    N, D = Q.shape\n",
        "    if K.shape != (N, D):\n",
        "        raise ValueError(f\"K must have shape {(N, D)}, got {tuple(K.shape)}\")\n",
        "    if V.shape != (N, D):\n",
        "        raise ValueError(f\"V must have shape {(N, D)}, got {tuple(V.shape)}\")\n",
        "\n",
        "    if Q.dtype not in (torch.float16, torch.bfloat16, torch.float32):\n",
        "        raise ValueError(f\"Q dtype must be fp16/bf16/fp32, got {Q.dtype}\")\n",
        "    if K.dtype != Q.dtype or V.dtype != Q.dtype:\n",
        "        raise ValueError(f\"K and V must have same dtype as Q (Q={Q.dtype}, K={K.dtype}, V={V.dtype})\")\n",
        "\n",
        "    # Optional but recommended: enforce same device\n",
        "    if K.device != Q.device or V.device != Q.device:\n",
        "        raise ValueError(f\"Q/K/V must be on the same device. Q={Q.device}, K={K.device}, V={V.device}\")\n",
        "\n",
        "    # -----------------------------\n",
        "    # Validate cfg (mini kernel assumption)\n",
        "    # -----------------------------\n",
        "    if cfg.BLOCK_M <= 0 or cfg.BLOCK_N <= 0:\n",
        "        raise ValueError(\"cfg.BLOCK_M and cfg.BLOCK_N must be positive\")\n",
        "    # This mini kernel (as written in our discussion) loads full D directly.\n",
        "    # If your kernel actually loops over D with BLOCK_D, you can relax this.\n",
        "    if cfg.BLOCK_D != D:\n",
        "        raise ValueError(f\"This mini wrapper expects cfg.BLOCK_D == D. Got BLOCK_D={cfg.BLOCK_D}, D={D}\")\n",
        "\n",
        "    # -----------------------------\n",
        "    # Mask handling\n",
        "    # -----------------------------\n",
        "    has_mask = mask is not None\n",
        "    is_causal = bool(causal)\n",
        "\n",
        "    if has_mask:\n",
        "        if mask.ndim != 2 or mask.shape != (N, N):\n",
        "            raise ValueError(f\"mask must be [N, N] = {(N, N)}, got {tuple(mask.shape)}\")\n",
        "        if not mask.is_cuda:\n",
        "            raise ValueError(f\"mask must be on CUDA, got {mask.device}\")\n",
        "        # For this mini wrapper, keep it simple: contiguous mask\n",
        "        if not mask.is_contiguous():\n",
        "            raise ValueError(\"mask must be contiguous for this mini wrapper\")\n",
        "        if mask.dtype not in (torch.float16, torch.bfloat16, torch.float32):\n",
        "            raise ValueError(f\"mask dtype must be fp16/bf16/fp32, got {mask.dtype}\")\n",
        "\n",
        "        mask_ptr = mask\n",
        "        stride_mn, stride_mm = mask.stride()\n",
        "    else:\n",
        "        # Kernel ignores mask_ptr when HAS_MASK=False; pass any valid pointer.\n",
        "        mask_ptr = Q\n",
        "        stride_mn, stride_mm = 0, 0\n",
        "\n",
        "    # -----------------------------\n",
        "    # Allocate output\n",
        "    # -----------------------------\n",
        "    out = torch.empty((N, D), device=Q.device, dtype=Q.dtype)\n",
        "\n",
        "    # -----------------------------\n",
        "    # Strides (in elements)\n",
        "    # -----------------------------\n",
        "    stride_qn, stride_qd = Q.stride()\n",
        "    stride_kn, stride_kd = K.stride()\n",
        "    stride_vn, stride_vd = V.stride()\n",
        "    stride_on, stride_od = out.stride()\n",
        "\n",
        "    # -----------------------------\n",
        "    # Launch params\n",
        "    # -----------------------------\n",
        "    grid = (triton.cdiv(N, cfg.BLOCK_M),)\n",
        "    scale = 1.0 / math.sqrt(D)\n",
        "\n",
        "    # -----------------------------\n",
        "    # Call kernel\n",
        "    # -----------------------------\n",
        "    flashattn_mini_kernel[grid](\n",
        "        Q, K, V, out,\n",
        "        mask_ptr,\n",
        "        N=N, D=D,\n",
        "        stride_qn=stride_qn, stride_qd=stride_qd,\n",
        "        stride_kn=stride_kn, stride_kd=stride_kd,\n",
        "        stride_vn=stride_vn, stride_vd=stride_vd,\n",
        "        stride_on=stride_on, stride_od=stride_od,\n",
        "        stride_mn=stride_mn, stride_mm=stride_mm,\n",
        "        BLOCK_M=cfg.BLOCK_M,\n",
        "        BLOCK_N=cfg.BLOCK_N,\n",
        "        BLOCK_D=cfg.BLOCK_D,\n",
        "        HAS_MASK=has_mask,\n",
        "        IS_CAUSAL=is_causal,\n",
        "        SCALE=scale,\n",
        "        num_warps=cfg.num_warps,\n",
        "        num_stages=1\n",
        "    )\n",
        "\n",
        "    return out\n",
        "\n",
        "# ============================================================\n",
        "# PyTorch reference + correctness\n",
        "# ============================================================\n",
        "def flashattn_ref_torch(\n",
        "    Q: torch.Tensor, K: torch.Tensor, V: torch.Tensor,\n",
        "    mask: Optional[torch.Tensor] = None,\n",
        "    causal: bool = False,\n",
        "):\n",
        "    \"\"\"\n",
        "    Reference attention in torch:\n",
        "      scores = Q @ K.T / sqrt(D)\n",
        "      if causal: apply causal mask\n",
        "      if mask: scores += mask\n",
        "      P = softmax(scores)\n",
        "      O = P @ V\n",
        "    \"\"\"\n",
        "    # TODO: implement reference (use fp32 for scores/softmax for stability)\n",
        "    # Notes:\n",
        "    #   - scores/softmax computed in fp32 for stability\n",
        "    #   - output returned in same dtype as Q\n",
        "\n",
        "    assert Q.ndim == 2 and K.ndim == 2 and V.ndim == 2\n",
        "    N, D = Q.shape\n",
        "    assert K.shape == (N, D) and V.shape == (N, D)\n",
        "\n",
        "    # fp32 scores for stability\n",
        "    q = Q.float()\n",
        "    k = K.float()\n",
        "    v = V.float()\n",
        "\n",
        "    scores = q @ k.transpose(0, 1)  # [N, N]\n",
        "    scores *= (1.0 / math.sqrt(D))\n",
        "\n",
        "    if causal:\n",
        "        # Upper triangle (j > i) set to -inf\n",
        "        # Use a bool mask and masked_fill for clarity.\n",
        "        causal_mask = torch.triu(torch.ones((N, N), device=Q.device, dtype=torch.bool), diagonal=1)\n",
        "        scores = scores.masked_fill(causal_mask, float(\"-inf\"))\n",
        "\n",
        "    if mask is not None:\n",
        "        assert mask.shape == (N, N), f\"mask must be [N, N], got {tuple(mask.shape)}\"\n",
        "        scores = scores + mask.float()\n",
        "\n",
        "    P = torch.softmax(scores, dim=-1)   # [N, N] fp32\n",
        "    O = P @ v                           # [N, D] fp32\n",
        "    return O.to(dtype=Q.dtype)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def check_correctness(\n",
        "    N=1024, D=64, dtype=torch.float16,\n",
        "    use_mask=False, causal=True,\n",
        "    cfg: FlashCfg = FlashCfg(BLOCK_M=64, BLOCK_N=64, BLOCK_D=64, num_warps=4),\n",
        "):\n",
        "    device = \"cuda\"\n",
        "    torch.manual_seed(0)\n",
        "\n",
        "    Q = torch.randn((N, D), device=device, dtype=dtype)\n",
        "    K = torch.randn((N, D), device=device, dtype=dtype)\n",
        "    V = torch.randn((N, D), device=device, dtype=dtype)\n",
        "\n",
        "    mask = None\n",
        "    if use_mask:\n",
        "        # TODO: create additive mask (e.g., padding or random -inf positions)\n",
        "        drop_prob = 0.05\n",
        "        drop = (torch.rand((N, N), device=device) < drop_prob)\n",
        "        mask = torch.zeros((N, N), device=device, dtype=torch.float32)\n",
        "        mask = mask.masked_fill(drop, float(\"-inf\"))\n",
        "\n",
        "        # Optional: don't mask diagonal to avoid degenerate rows\n",
        "        diag = torch.eye(N, device=device, dtype=torch.bool)\n",
        "        mask = mask.masked_fill(diag, 0.0)\n",
        "\n",
        "    # TODO:\n",
        "    # - out_ref = flashattn_ref_torch(...)\n",
        "    # - out_tri = flashattn_mini_triton(...)\n",
        "    # - print max/mean abs error\n",
        "    out_ref = flashattn_ref_torch(Q, K, V, mask=mask, causal=causal)\n",
        "    out_tri = flashattn_mini_triton(Q, K, V, mask=mask, causal=causal, cfg=cfg)\n",
        "\n",
        "    # Compare in fp32 for reporting\n",
        "    diff = (out_ref.float() - out_tri.float()).abs()\n",
        "    max_abs = diff.max().item()\n",
        "    mean_abs = diff.mean().item()\n",
        "\n",
        "    print(f\"N={N}, D={D}, dtype={dtype}, use_mask={use_mask}, causal={causal}\")\n",
        "    print(f\"max_abs_err = {max_abs:.3e}\")\n",
        "    print(f\"mean_abs_err = {mean_abs:.3e}\")\n",
        "\n",
        "    return max_abs, mean_abs\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Benchmark: compare naive vs flash\n",
        "# ============================================================\n",
        "def cuda_time_ms(fn, iters=30, warmup=10) -> float:\n",
        "    for _ in range(warmup):\n",
        "        fn()\n",
        "    torch.cuda.synchronize()\n",
        "\n",
        "    s = torch.cuda.Event(enable_timing=True)\n",
        "    e = torch.cuda.Event(enable_timing=True)\n",
        "\n",
        "    s.record()\n",
        "    for _ in range(iters):\n",
        "        fn()\n",
        "    e.record()\n",
        "    torch.cuda.synchronize()\n",
        "    return s.elapsed_time(e) / iters\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def compare_perf(\n",
        "    N_list: List[int] = [256, 512, 1024, 2048],\n",
        "    D: int = 64,\n",
        "    dtype=torch.float16,\n",
        "    causal: bool = True,\n",
        "    cfg_flash: FlashCfg = FlashCfg(BLOCK_M=64, BLOCK_N=64, BLOCK_D=64, num_warps=4),\n",
        "    cfg_naive: Optional[Dict[str, Any]] = None,\n",
        "):\n",
        "    device = \"cuda\"\n",
        "    torch.manual_seed(0)\n",
        "\n",
        "    print(\"| N | Impl | ms | speedup_vs_naive |\")\n",
        "    print(\"|---|------|----|------------------|\")\n",
        "\n",
        "    for N in N_list:\n",
        "        Q = torch.randn((N, D), device=device, dtype=dtype)\n",
        "        K = torch.randn((N, D), device=device, dtype=dtype)\n",
        "        V = torch.randn((N, D), device=device, dtype=dtype)\n",
        "\n",
        "        mask = None\n",
        "        if causal:\n",
        "            # For naive attention you may need a materialized mask; for flash you might do internal causal.\n",
        "            # TODO: create mask for naive if required by your implementation.\n",
        "            pass\n",
        "\n",
        "        # --- naive ---\n",
        "        def fn_naive():\n",
        "            return naive_attention_triton(Q, K, V, mask=mask, cfg=cfg_naive)\n",
        "\n",
        "        # --- flash ---\n",
        "        def fn_flash():\n",
        "            return flashattn_mini_triton(Q, K, V, mask=None, causal=causal, cfg=cfg_flash)\n",
        "\n",
        "        # TODO: optionally benchmark torch reference too\n",
        "        ms_naive = cuda_time_ms(fn_naive)\n",
        "        ms_flash = cuda_time_ms(fn_flash)\n",
        "\n",
        "        speedup = ms_naive / ms_flash if ms_flash > 0 else float(\"inf\")\n",
        "\n",
        "        print(f\"| {N} | naive | {ms_naive:.4f} | 1.00x |\")\n",
        "        print(f\"| {N} | flash | {ms_flash:.4f} | {speedup:.2f}x |\")\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Main\n",
        "# ============================================================\n",
        "def main():\n",
        "    if not torch.cuda.is_available():\n",
        "        raise RuntimeError(\"CUDA required.\")\n",
        "\n",
        "    # TODO: run correctness first on small N\n",
        "    check_correctness(N=256, D=64, causal=True, use_mask=False)\n",
        "\n",
        "    # TODO: then benchmark scaling\n",
        "    compare_perf(N_list=[256, 512, 1024, 1024], D=64)\n",
        "\n",
        "    # raise NotImplementedError(\"TODO: wire up your kernels and run correctness/bench\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# day6_flashattention_v1_vs_v2_splitk.py\n",
        "# ============================================================\n",
        "# FlashAttention v1 (single kernel) vs v2-style split-K (2 kernels)\n",
        "# - correctness vs torch\n",
        "# - perf benchmark (v1 vs v2)\n",
        "#\n",
        "# Notes for Tesla T4:\n",
        "# - T4 shared memory per block limit: 64KB\n",
        "# - Keep BLOCK_N modest (e.g., 64) and num_stages=1 first.\n",
        "# ============================================================\n",
        "\n",
        "from __future__ import annotations\n",
        "import math\n",
        "from dataclasses import dataclass\n",
        "from typing import Optional, List\n",
        "\n",
        "import torch\n",
        "import triton\n",
        "import triton.language as tl\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Utilities\n",
        "# ============================================================\n",
        "def _assert_2d(x: torch.Tensor, name: str) -> None:\n",
        "    if not isinstance(x, torch.Tensor):\n",
        "        raise TypeError(f\"{name} must be a torch.Tensor, got {type(x)}\")\n",
        "    if x.ndim != 2:\n",
        "        raise ValueError(f\"{name} must be 2D [N, D], got shape {tuple(x.shape)}\")\n",
        "\n",
        "\n",
        "def _assert_cuda_contig(x: torch.Tensor, name: str) -> None:\n",
        "    if not x.is_cuda:\n",
        "        raise ValueError(f\"{name} must be on CUDA, got {x.device}\")\n",
        "    if not x.is_contiguous():\n",
        "        raise ValueError(f\"{name} must be contiguous, got strides {x.stride()} and shape {tuple(x.shape)}\")\n",
        "\n",
        "\n",
        "def _out_tl_dtype_from_torch(dtype: torch.dtype):\n",
        "    # Map torch dtype -> triton tl dtype (constexpr friendly)\n",
        "    if dtype == torch.float16:\n",
        "        return tl.float16\n",
        "    if dtype == torch.bfloat16:\n",
        "        return tl.bfloat16\n",
        "    if dtype == torch.float32:\n",
        "        return tl.float32\n",
        "    raise ValueError(f\"Unsupported dtype {dtype}\")\n",
        "\n",
        "\n",
        "def cuda_time_ms(fn, iters=30, warmup=10) -> float:\n",
        "    for _ in range(warmup):\n",
        "        fn()\n",
        "    torch.cuda.synchronize()\n",
        "    s = torch.cuda.Event(enable_timing=True)\n",
        "    e = torch.cuda.Event(enable_timing=True)\n",
        "    s.record()\n",
        "    for _ in range(iters):\n",
        "        fn()\n",
        "    e.record()\n",
        "    torch.cuda.synchronize()\n",
        "    return s.elapsed_time(e) / iters\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# v1 Config\n",
        "# ============================================================\n",
        "@dataclass(frozen=True)\n",
        "class FlashV1Cfg:\n",
        "    BLOCK_M: int = 64\n",
        "    BLOCK_N: int = 64   # T4-safe starter\n",
        "    BLOCK_D: int = 64\n",
        "    num_warps: int = 4\n",
        "    num_stages: int = 1  # T4-safe starter\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# v1 Kernel (single kernel)\n",
        "# ============================================================\n",
        "@triton.jit\n",
        "def flashattn_v1_kernel(\n",
        "    q_ptr, k_ptr, v_ptr, o_ptr,\n",
        "    mask_ptr,\n",
        "    N: tl.constexpr, D: tl.constexpr,\n",
        "    stride_qn: tl.constexpr, stride_qd: tl.constexpr,\n",
        "    stride_kn: tl.constexpr, stride_kd: tl.constexpr,\n",
        "    stride_vn: tl.constexpr, stride_vd: tl.constexpr,\n",
        "    stride_on: tl.constexpr, stride_od: tl.constexpr,\n",
        "    stride_mn: tl.constexpr, stride_mm: tl.constexpr,\n",
        "    BLOCK_M: tl.constexpr,\n",
        "    BLOCK_N: tl.constexpr,\n",
        "    BLOCK_D: tl.constexpr,\n",
        "    HAS_MASK: tl.constexpr,\n",
        "    IS_CAUSAL: tl.constexpr,\n",
        "    SCALE: tl.constexpr,\n",
        "    OUT_DTYPE: tl.constexpr,\n",
        "):\n",
        "    pid = tl.program_id(axis=0)\n",
        "    m_start = pid * BLOCK_M\n",
        "\n",
        "    row = m_start + tl.arange(0, BLOCK_M)                  # [BM]\n",
        "    row_mask = row < N\n",
        "\n",
        "    d = tl.arange(0, D)                                    # [D]\n",
        "    d_mask = d < D\n",
        "    q_ptrs = q_ptr + row[:, None] * stride_qn + d[None, :] * stride_qd\n",
        "    q = tl.load(q_ptrs, mask=row_mask[:, None] & d_mask[None, :], other=0.0).to(tl.float32)  # [BM, D]\n",
        "\n",
        "    m = tl.full([BLOCK_M], -float(\"inf\"), tl.float32)      # [BM]\n",
        "    l = tl.zeros([BLOCK_M], tl.float32)                    # [BM]\n",
        "    acc = tl.zeros([BLOCK_M, D], tl.float32)               # [BM, D]\n",
        "\n",
        "    # stream over all keys\n",
        "    for n_start in range(0, N, BLOCK_N):\n",
        "        col = n_start + tl.arange(0, BLOCK_N)              # [BN]\n",
        "        col_mask = col < N\n",
        "\n",
        "        k_ptrs = k_ptr + col[:, None] * stride_kn + d[None, :] * stride_kd\n",
        "        v_ptrs = v_ptr + col[:, None] * stride_vn + d[None, :] * stride_vd\n",
        "        k = tl.load(k_ptrs, mask=col_mask[:, None] & d_mask[None, :], other=0.0).to(tl.float32)  # [BN, D]\n",
        "        v = tl.load(v_ptrs, mask=col_mask[:, None] & d_mask[None, :], other=0.0).to(tl.float32)  # [BN, D]\n",
        "\n",
        "        scores = tl.dot(q, tl.trans(k)) * SCALE            # [BM, BN], fp32\n",
        "\n",
        "        # causal mask: keep only col <= row (global indices!)\n",
        "        if IS_CAUSAL:\n",
        "            keep = (col[None, :] <= row[:, None]) & (row_mask[:, None] & col_mask[None, :])\n",
        "            scores = tl.where(keep, scores, -float(\"inf\"))\n",
        "        else:\n",
        "            # still ensure OOB columns don't contribute\n",
        "            scores = tl.where(row_mask[:, None] & col_mask[None, :], scores, -float(\"inf\"))\n",
        "\n",
        "        if HAS_MASK:\n",
        "            mptrs = mask_ptr + row[:, None] * stride_mn + col[None, :] * stride_mm\n",
        "            mvals = tl.load(mptrs, mask=row_mask[:, None] & col_mask[None, :], other=0.0).to(tl.float32)\n",
        "            scores = scores + mvals\n",
        "\n",
        "        s_max = tl.max(scores, axis=1)                     # [BM]\n",
        "        m_new = tl.maximum(m, s_max)                       # [BM]\n",
        "        alpha = tl.exp(m - m_new)                          # [BM]\n",
        "        p = tl.exp(scores - m_new[:, None])                # [BM, BN]\n",
        "\n",
        "        l_new = l * alpha + tl.sum(p, axis=1)              # [BM]\n",
        "        acc = acc * alpha[:, None] + tl.dot(p, v)          # [BM, D]\n",
        "\n",
        "        m = m_new\n",
        "        l = l_new\n",
        "\n",
        "    out = acc / l[:, None]                                 # [BM, D]\n",
        "    o_ptrs = o_ptr + row[:, None] * stride_on + d[None, :] * stride_od\n",
        "    tl.store(o_ptrs, out.to(OUT_DTYPE), mask=row_mask[:, None] & d_mask[None, :])\n",
        "\n",
        "\n",
        "def flashattn_v1_triton(\n",
        "    Q: torch.Tensor, K: torch.Tensor, V: torch.Tensor,\n",
        "    mask: Optional[torch.Tensor] = None,\n",
        "    causal: bool = False,\n",
        "    cfg: FlashV1Cfg = FlashV1Cfg(),\n",
        ") -> torch.Tensor:\n",
        "    _assert_2d(Q, \"Q\"); _assert_2d(K, \"K\"); _assert_2d(V, \"V\")\n",
        "    _assert_cuda_contig(Q, \"Q\"); _assert_cuda_contig(K, \"K\"); _assert_cuda_contig(V, \"V\")\n",
        "    N, D = Q.shape\n",
        "    if K.shape != (N, D) or V.shape != (N, D):\n",
        "        raise ValueError(\"K,V must match Q shape\")\n",
        "    if cfg.BLOCK_D != D:\n",
        "        raise ValueError(f\"Mini assumes BLOCK_D == D. Got {cfg.BLOCK_D} vs D={D}\")\n",
        "    if Q.dtype not in (torch.float16, torch.bfloat16, torch.float32):\n",
        "        raise ValueError(\"Q dtype must be fp16/bf16/fp32\")\n",
        "    if K.dtype != Q.dtype or V.dtype != Q.dtype:\n",
        "        raise ValueError(\"K and V must match Q dtype\")\n",
        "\n",
        "    has_mask = mask is not None\n",
        "    if has_mask:\n",
        "        if mask.shape != (N, N) or (not mask.is_cuda) or (not mask.is_contiguous()):\n",
        "            raise ValueError(\"mask must be CUDA contiguous and shape [N,N]\")\n",
        "        stride_mn, stride_mm = mask.stride()\n",
        "        mask_ptr = mask\n",
        "    else:\n",
        "        mask_ptr = Q\n",
        "        stride_mn, stride_mm = 0, 0\n",
        "\n",
        "    out = torch.empty((N, D), device=Q.device, dtype=Q.dtype)\n",
        "\n",
        "    stride_qn, stride_qd = Q.stride()\n",
        "    stride_kn, stride_kd = K.stride()\n",
        "    stride_vn, stride_vd = V.stride()\n",
        "    stride_on, stride_od = out.stride()\n",
        "\n",
        "    grid = (triton.cdiv(N, cfg.BLOCK_M),)\n",
        "    scale = 1.0 / math.sqrt(D)\n",
        "    out_tl_dtype = _out_tl_dtype_from_torch(Q.dtype)\n",
        "\n",
        "    flashattn_v1_kernel[grid](\n",
        "        Q, K, V, out,\n",
        "        mask_ptr,\n",
        "        N=N, D=D,\n",
        "        stride_qn=stride_qn, stride_qd=stride_qd,\n",
        "        stride_kn=stride_kn, stride_kd=stride_kd,\n",
        "        stride_vn=stride_vn, stride_vd=stride_vd,\n",
        "        stride_on=stride_on, stride_od=stride_od,\n",
        "        stride_mn=stride_mn, stride_mm=stride_mm,\n",
        "        BLOCK_M=cfg.BLOCK_M, BLOCK_N=cfg.BLOCK_N, BLOCK_D=cfg.BLOCK_D,\n",
        "        HAS_MASK=has_mask, IS_CAUSAL=bool(causal),\n",
        "        SCALE=scale,\n",
        "        OUT_DTYPE=out_tl_dtype,\n",
        "        num_warps=cfg.num_warps,\n",
        "        num_stages=cfg.num_stages,\n",
        "    )\n",
        "    return out\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# v2 Config (split-K)\n",
        "# ============================================================\n",
        "@dataclass(frozen=True)\n",
        "class FlashV2Cfg:\n",
        "    BLOCK_M: int = 64\n",
        "    BLOCK_N: int = 64      # T4-safe starter\n",
        "    BLOCK_D: int = 64\n",
        "    num_splits: int = 4    # split-K parallelism\n",
        "    num_warps: int = 4\n",
        "    num_stages: int = 1    # T4-safe starter\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# v2 Stage 1: (Q-block, split) -> partial (m_s, l_s, acc_s)\n",
        "# ============================================================\n",
        "@triton.jit\n",
        "def flashattn_v2_stage1_kernel(\n",
        "    q_ptr, k_ptr, v_ptr,\n",
        "    mask_ptr,\n",
        "    m_partial_ptr,\n",
        "    l_partial_ptr,\n",
        "    acc_partial_ptr,\n",
        "    N: tl.constexpr, D: tl.constexpr,\n",
        "\n",
        "    stride_qn: tl.constexpr, stride_qd: tl.constexpr,\n",
        "    stride_kn: tl.constexpr, stride_kd: tl.constexpr,\n",
        "    stride_vn: tl.constexpr, stride_vd: tl.constexpr,\n",
        "    stride_mn: tl.constexpr, stride_mm: tl.constexpr,\n",
        "\n",
        "    STRIDE_PM_QB: tl.constexpr,\n",
        "    STRIDE_PM_SPLIT: tl.constexpr,\n",
        "\n",
        "    STRIDE_PL_QB: tl.constexpr,\n",
        "    STRIDE_PL_SPLIT: tl.constexpr,\n",
        "\n",
        "    STRIDE_PACC_QB: tl.constexpr,\n",
        "    STRIDE_PACC_SPLIT: tl.constexpr,\n",
        "    STRIDE_PACC_M: tl.constexpr,\n",
        "    STRIDE_PACC_D: tl.constexpr,\n",
        "\n",
        "    BLOCK_M: tl.constexpr,\n",
        "    BLOCK_N: tl.constexpr,\n",
        "    BLOCK_D: tl.constexpr,\n",
        "    NUM_SPLITS: tl.constexpr,\n",
        "\n",
        "    HAS_MASK: tl.constexpr,\n",
        "    IS_CAUSAL: tl.constexpr,\n",
        "    SCALE: tl.constexpr,\n",
        "):\n",
        "    pid_qb = tl.program_id(0)   # Q-block id\n",
        "    pid_s  = tl.program_id(1)   # split id\n",
        "\n",
        "    m_start = pid_qb * BLOCK_M\n",
        "    row = m_start + tl.arange(0, BLOCK_M)               # [BM]\n",
        "    row_mask = row < N\n",
        "\n",
        "    d = tl.arange(0, D)\n",
        "    d_mask = d < D\n",
        "\n",
        "    # split range\n",
        "    chunk = (N + NUM_SPLITS - 1) // NUM_SPLITS         # constexpr arithmetic\n",
        "    k_start = pid_s * chunk\n",
        "    k_end = tl.minimum(N, (pid_s + 1) * chunk)\n",
        "\n",
        "    # load Q tile\n",
        "    q_ptrs = q_ptr + row[:, None] * stride_qn + d[None, :] * stride_qd\n",
        "    q = tl.load(q_ptrs, mask=row_mask[:, None] & d_mask[None, :], other=0.0).to(tl.float32)  # [BM, D]\n",
        "\n",
        "    # online softmax state for this split\n",
        "    m = tl.full([BLOCK_M], -float(\"inf\"), tl.float32)\n",
        "    l = tl.zeros([BLOCK_M], tl.float32)\n",
        "    acc = tl.zeros([BLOCK_M, D], tl.float32)\n",
        "\n",
        "    # number of tiles within one split chunk (compile-time)\n",
        "    num_tiles = (chunk + BLOCK_N - 1) // BLOCK_N\n",
        "\n",
        "    # iterate tiles inside [k_start, k_end)\n",
        "    for n_start in range(0, N, BLOCK_N):\n",
        "        col = n_start + tl.arange(0, BLOCK_N)           # [BN]\n",
        "        col_valid = (col >= k_start) & (col < k_end) & (col < N)\n",
        "\n",
        "        k_ptrs = k_ptr + col[:, None] * stride_kn + d[None, :] * stride_kd\n",
        "        v_ptrs = v_ptr + col[:, None] * stride_vn + d[None, :] * stride_vd\n",
        "        k = tl.load(k_ptrs, mask=col_valid[:, None] & d_mask[None, :], other=0.0).to(tl.float32)  # [BN, D]\n",
        "        v = tl.load(v_ptrs, mask=col_valid[:, None] & d_mask[None, :], other=0.0).to(tl.float32)  # [BN, D]\n",
        "\n",
        "        scores = tl.dot(q, tl.trans(k)) * SCALE         # [BM, BN]\n",
        "\n",
        "        if IS_CAUSAL:\n",
        "            keep = (col[None, :] <= row[:, None]) & (row_mask[:, None] & col_valid[None, :])\n",
        "            scores = tl.where(keep, scores, -float(\"inf\"))\n",
        "        else:\n",
        "            scores = tl.where(row_mask[:, None] & col_valid[None, :], scores, -float(\"inf\"))\n",
        "\n",
        "        if HAS_MASK:\n",
        "            mptrs = mask_ptr + row[:, None] * stride_mn + col[None, :] * stride_mm\n",
        "            mvals = tl.load(mptrs, mask=row_mask[:, None] & col_valid[None, :], other=0.0).to(tl.float32)\n",
        "            scores = scores + mvals\n",
        "\n",
        "        s_max = tl.max(scores, axis=1)\n",
        "        m_new = tl.maximum(m, s_max)\n",
        "        alpha = tl.exp(m - m_new)\n",
        "        p = tl.exp(scores - m_new[:, None])\n",
        "\n",
        "        l_new = l * alpha + tl.sum(p, axis=1)\n",
        "        acc = acc * alpha[:, None] + tl.dot(p, v)\n",
        "\n",
        "        m = m_new\n",
        "        l = l_new\n",
        "\n",
        "    # store partials\n",
        "    offs_m = tl.arange(0, BLOCK_M)\n",
        "\n",
        "    pm_ptrs = m_partial_ptr + pid_qb * STRIDE_PM_QB + pid_s * STRIDE_PM_SPLIT + offs_m\n",
        "    pl_ptrs = l_partial_ptr + pid_qb * STRIDE_PL_QB + pid_s * STRIDE_PL_SPLIT + offs_m\n",
        "    tl.store(pm_ptrs, m, mask=row_mask)\n",
        "    tl.store(pl_ptrs, l, mask=row_mask)\n",
        "\n",
        "    pacc_ptrs = (\n",
        "        acc_partial_ptr\n",
        "        + pid_qb * STRIDE_PACC_QB\n",
        "        + pid_s * STRIDE_PACC_SPLIT\n",
        "        + offs_m[:, None] * STRIDE_PACC_M\n",
        "        + d[None, :] * STRIDE_PACC_D\n",
        "    )\n",
        "    tl.store(pacc_ptrs, acc, mask=row_mask[:, None] & d_mask[None, :])\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# v2 Stage 2: merge splits -> final O\n",
        "# ============================================================\n",
        "@triton.jit\n",
        "def flashattn_v2_stage2_kernel(\n",
        "    o_ptr,\n",
        "    m_partial_ptr,\n",
        "    l_partial_ptr,\n",
        "    acc_partial_ptr,\n",
        "    N: tl.constexpr, D: tl.constexpr,\n",
        "\n",
        "    stride_on: tl.constexpr, stride_od: tl.constexpr,\n",
        "\n",
        "    STRIDE_PM_QB: tl.constexpr,\n",
        "    STRIDE_PM_SPLIT: tl.constexpr,\n",
        "\n",
        "    STRIDE_PL_QB: tl.constexpr,\n",
        "    STRIDE_PL_SPLIT: tl.constexpr,\n",
        "\n",
        "    STRIDE_PACC_QB: tl.constexpr,\n",
        "    STRIDE_PACC_SPLIT: tl.constexpr,\n",
        "    STRIDE_PACC_M: tl.constexpr,\n",
        "    STRIDE_PACC_D: tl.constexpr,\n",
        "\n",
        "    BLOCK_M: tl.constexpr,\n",
        "    BLOCK_D: tl.constexpr,\n",
        "    NUM_SPLITS: tl.constexpr,\n",
        "    OUT_DTYPE: tl.constexpr,\n",
        "):\n",
        "    pid_qb = tl.program_id(0)\n",
        "    m_start = pid_qb * BLOCK_M\n",
        "    row = m_start + tl.arange(0, BLOCK_M)               # [BM]\n",
        "    row_mask = row < N\n",
        "\n",
        "    d = tl.arange(0, D)\n",
        "    d_mask = d < D\n",
        "\n",
        "    # 1) merged m = max_s m_s\n",
        "    m_merged = tl.full([BLOCK_M], -float(\"inf\"), tl.float32)\n",
        "    offs_m = tl.arange(0, BLOCK_M)\n",
        "    for s in tl.static_range(0, NUM_SPLITS):\n",
        "        pm_ptrs = m_partial_ptr + pid_qb * STRIDE_PM_QB + s * STRIDE_PM_SPLIT + offs_m\n",
        "        m_s = tl.load(pm_ptrs, mask=row_mask, other=-float(\"inf\"))\n",
        "        m_merged = tl.maximum(m_merged, m_s)\n",
        "\n",
        "    # 2) merged l and acc\n",
        "    l_merged = tl.zeros([BLOCK_M], tl.float32)\n",
        "    acc_merged = tl.zeros([BLOCK_M, D], tl.float32)\n",
        "\n",
        "    for s in tl.static_range(0, NUM_SPLITS):\n",
        "        pm_ptrs = m_partial_ptr + pid_qb * STRIDE_PM_QB + s * STRIDE_PM_SPLIT + offs_m\n",
        "        pl_ptrs = l_partial_ptr + pid_qb * STRIDE_PL_QB + s * STRIDE_PL_SPLIT + offs_m\n",
        "        m_s = tl.load(pm_ptrs, mask=row_mask, other=-float(\"inf\"))\n",
        "        l_s = tl.load(pl_ptrs, mask=row_mask, other=0.0)\n",
        "\n",
        "        w = tl.exp(m_s - m_merged)                      # [BM]\n",
        "        l_merged += l_s * w\n",
        "\n",
        "        pacc_ptrs = (\n",
        "            acc_partial_ptr\n",
        "            + pid_qb * STRIDE_PACC_QB\n",
        "            + s * STRIDE_PACC_SPLIT\n",
        "            + offs_m[:, None] * STRIDE_PACC_M\n",
        "            + d[None, :] * STRIDE_PACC_D\n",
        "        )\n",
        "        acc_s = tl.load(pacc_ptrs, mask=row_mask[:, None] & d_mask[None, :], other=0.0)\n",
        "        acc_merged += acc_s * w[:, None]\n",
        "\n",
        "    out = acc_merged / l_merged[:, None]\n",
        "    o_ptrs = o_ptr + row[:, None] * stride_on + d[None, :] * stride_od\n",
        "    tl.store(o_ptrs, out.to(OUT_DTYPE), mask=row_mask[:, None] & d_mask[None, :])\n",
        "\n",
        "\n",
        "def flashattn_v2_splitk_triton(\n",
        "    Q: torch.Tensor, K: torch.Tensor, V: torch.Tensor,\n",
        "    mask: Optional[torch.Tensor] = None,\n",
        "    causal: bool = False,\n",
        "    cfg: FlashV2Cfg = FlashV2Cfg(),\n",
        ") -> torch.Tensor:\n",
        "    _assert_2d(Q, \"Q\"); _assert_2d(K, \"K\"); _assert_2d(V, \"V\")\n",
        "    _assert_cuda_contig(Q, \"Q\"); _assert_cuda_contig(K, \"K\"); _assert_cuda_contig(V, \"V\")\n",
        "    N, D = Q.shape\n",
        "    if K.shape != (N, D) or V.shape != (N, D):\n",
        "        raise ValueError(\"K,V must match Q shape\")\n",
        "    if cfg.BLOCK_D != D:\n",
        "        raise ValueError(f\"Mini assumes BLOCK_D == D. Got {cfg.BLOCK_D} vs D={D}\")\n",
        "\n",
        "    if Q.dtype not in (torch.float16, torch.bfloat16, torch.float32):\n",
        "        raise ValueError(\"Q dtype must be fp16/bf16/fp32\")\n",
        "    if K.dtype != Q.dtype or V.dtype != Q.dtype:\n",
        "        raise ValueError(\"K and V must match Q dtype\")\n",
        "\n",
        "    has_mask = mask is not None\n",
        "    if has_mask:\n",
        "        if mask.shape != (N, N) or (not mask.is_cuda) or (not mask.is_contiguous()):\n",
        "            raise ValueError(\"mask must be CUDA contiguous and shape [N,N]\")\n",
        "        stride_mn, stride_mm = mask.stride()\n",
        "        mask_ptr = mask\n",
        "    else:\n",
        "        mask_ptr = Q\n",
        "        stride_mn, stride_mm = 0, 0\n",
        "\n",
        "    out = torch.empty((N, D), device=Q.device, dtype=Q.dtype)\n",
        "\n",
        "    num_qb = triton.cdiv(N, cfg.BLOCK_M)\n",
        "    num_splits = cfg.num_splits\n",
        "\n",
        "    # partial buffers in fp32\n",
        "    m_partial = torch.empty((num_qb, num_splits, cfg.BLOCK_M), device=Q.device, dtype=torch.float32)\n",
        "    l_partial = torch.empty((num_qb, num_splits, cfg.BLOCK_M), device=Q.device, dtype=torch.float32)\n",
        "    acc_partial = torch.empty((num_qb, num_splits, cfg.BLOCK_M, D), device=Q.device, dtype=torch.float32)\n",
        "\n",
        "    # strides (elements)\n",
        "    STRIDE_PM_QB, STRIDE_PM_SPLIT, _ = m_partial.stride()\n",
        "    STRIDE_PL_QB, STRIDE_PL_SPLIT, _ = l_partial.stride()\n",
        "    STRIDE_PACC_QB, STRIDE_PACC_SPLIT, STRIDE_PACC_M, STRIDE_PACC_D = acc_partial.stride()\n",
        "\n",
        "    stride_qn, stride_qd = Q.stride()\n",
        "    stride_kn, stride_kd = K.stride()\n",
        "    stride_vn, stride_vd = V.stride()\n",
        "    stride_on, stride_od = out.stride()\n",
        "\n",
        "    scale = 1.0 / math.sqrt(D)\n",
        "    out_tl_dtype = _out_tl_dtype_from_torch(Q.dtype)\n",
        "\n",
        "    # Stage 1: 2D grid\n",
        "    grid1 = (num_qb, num_splits)\n",
        "    flashattn_v2_stage1_kernel[grid1](\n",
        "        Q, K, V,\n",
        "        mask_ptr,\n",
        "        m_partial, l_partial, acc_partial,\n",
        "        N=N, D=D,\n",
        "        stride_qn=stride_qn, stride_qd=stride_qd,\n",
        "        stride_kn=stride_kn, stride_kd=stride_kd,\n",
        "        stride_vn=stride_vn, stride_vd=stride_vd,\n",
        "        stride_mn=stride_mn, stride_mm=stride_mm,\n",
        "        STRIDE_PM_QB=STRIDE_PM_QB, STRIDE_PM_SPLIT=STRIDE_PM_SPLIT,\n",
        "        STRIDE_PL_QB=STRIDE_PL_QB, STRIDE_PL_SPLIT=STRIDE_PL_SPLIT,\n",
        "        STRIDE_PACC_QB=STRIDE_PACC_QB, STRIDE_PACC_SPLIT=STRIDE_PACC_SPLIT,\n",
        "        STRIDE_PACC_M=STRIDE_PACC_M, STRIDE_PACC_D=STRIDE_PACC_D,\n",
        "        BLOCK_M=cfg.BLOCK_M, BLOCK_N=cfg.BLOCK_N, BLOCK_D=cfg.BLOCK_D,\n",
        "        NUM_SPLITS=num_splits,\n",
        "        HAS_MASK=has_mask, IS_CAUSAL=bool(causal),\n",
        "        SCALE=scale,\n",
        "        num_warps=cfg.num_warps,\n",
        "        num_stages=cfg.num_stages,\n",
        "    )\n",
        "\n",
        "    # Stage 2: 1D grid\n",
        "    grid2 = (num_qb,)\n",
        "    flashattn_v2_stage2_kernel[grid2](\n",
        "        out,\n",
        "        m_partial, l_partial, acc_partial,\n",
        "        N=N, D=D,\n",
        "        stride_on=stride_on, stride_od=stride_od,\n",
        "        STRIDE_PM_QB=STRIDE_PM_QB, STRIDE_PM_SPLIT=STRIDE_PM_SPLIT,\n",
        "        STRIDE_PL_QB=STRIDE_PL_QB, STRIDE_PL_SPLIT=STRIDE_PL_SPLIT,\n",
        "        STRIDE_PACC_QB=STRIDE_PACC_QB, STRIDE_PACC_SPLIT=STRIDE_PACC_SPLIT,\n",
        "        STRIDE_PACC_M=STRIDE_PACC_M, STRIDE_PACC_D=STRIDE_PACC_D,\n",
        "        BLOCK_M=cfg.BLOCK_M, BLOCK_D=cfg.BLOCK_D,\n",
        "        NUM_SPLITS=num_splits,\n",
        "        OUT_DTYPE=out_tl_dtype,\n",
        "        num_warps=cfg.num_warps,\n",
        "    )\n",
        "    return out\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Torch reference (correctness)\n",
        "# ============================================================\n",
        "def flashattn_ref_torch(\n",
        "    Q: torch.Tensor, K: torch.Tensor, V: torch.Tensor,\n",
        "    mask: Optional[torch.Tensor] = None,\n",
        "    causal: bool = False,\n",
        ") -> torch.Tensor:\n",
        "    _assert_2d(Q, \"Q\"); _assert_2d(K, \"K\"); _assert_2d(V, \"V\")\n",
        "    N, D = Q.shape\n",
        "    q = Q.float()\n",
        "    k = K.float()\n",
        "    v = V.float()\n",
        "\n",
        "    scores = (q @ k.transpose(0, 1)) * (1.0 / math.sqrt(D))\n",
        "    if causal:\n",
        "        cm = torch.triu(torch.ones((N, N), device=Q.device, dtype=torch.bool), diagonal=1)\n",
        "        scores = scores.masked_fill(cm, float(\"-inf\"))\n",
        "    if mask is not None:\n",
        "        scores = scores + mask.float()\n",
        "\n",
        "    P = torch.softmax(scores, dim=-1)\n",
        "    O = P @ v\n",
        "    return O.to(dtype=Q.dtype)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def check_correctness(\n",
        "    N=1024, D=64, dtype=torch.float16,\n",
        "    use_mask=False, causal=True,\n",
        "    cfg_v1: FlashV1Cfg = FlashV1Cfg(),\n",
        "    cfg_v2: FlashV2Cfg = FlashV2Cfg(),\n",
        "):\n",
        "    device = \"cuda\"\n",
        "    torch.manual_seed(0)\n",
        "\n",
        "    Q = torch.randn((N, D), device=device, dtype=dtype)\n",
        "    K = torch.randn((N, D), device=device, dtype=dtype)\n",
        "    V = torch.randn((N, D), device=device, dtype=dtype)\n",
        "\n",
        "    mask = None\n",
        "    if use_mask:\n",
        "        drop_prob = 0.05\n",
        "        drop = (torch.rand((N, N), device=device) < drop_prob)\n",
        "        mask = torch.zeros((N, N), device=device, dtype=torch.float32)\n",
        "        mask = mask.masked_fill(drop, float(\"-inf\"))\n",
        "        diag = torch.eye(N, device=device, dtype=torch.bool)\n",
        "        mask = mask.masked_fill(diag, 0.0)\n",
        "\n",
        "    out_ref = flashattn_ref_torch(Q, K, V, mask=mask, causal=causal)\n",
        "    out_v1 = flashattn_v1_triton(Q, K, V, mask=mask, causal=causal, cfg=cfg_v1)\n",
        "    out_v2 = flashattn_v2_splitk_triton(Q, K, V, mask=mask, causal=causal, cfg=cfg_v2)\n",
        "\n",
        "    diff1 = (out_ref.float() - out_v1.float()).abs()\n",
        "    diff2 = (out_ref.float() - out_v2.float()).abs()\n",
        "\n",
        "    print(f\"[Correctness] N={N} D={D} dtype={dtype} use_mask={use_mask} causal={causal}\")\n",
        "    print(f\"  v1 max_abs={diff1.max().item():.3e} mean_abs={diff1.mean().item():.3e}\")\n",
        "    print(f\"  v2 max_abs={diff2.max().item():.3e} mean_abs={diff2.mean().item():.3e}\")\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def compare_perf(\n",
        "    N_list: List[int] = [256, 512, 1024, 2048],\n",
        "    D: int = 64,\n",
        "    dtype=torch.float16,\n",
        "    causal: bool = True,\n",
        "    cfg_v1: FlashV1Cfg = FlashV1Cfg(),\n",
        "    cfg_v2: FlashV2Cfg = FlashV2Cfg(),\n",
        "):\n",
        "    device = \"cuda\"\n",
        "    torch.manual_seed(0)\n",
        "\n",
        "    print(\"| N | v1 ms | v2 ms | v2/v1 speedup |\")\n",
        "    print(\"|---|------:|------:|--------------:|\")\n",
        "\n",
        "    for N in N_list:\n",
        "        Q = torch.randn((N, D), device=device, dtype=dtype)\n",
        "        K = torch.randn((N, D), device=device, dtype=dtype)\n",
        "        V = torch.randn((N, D), device=device, dtype=dtype)\n",
        "\n",
        "        # no materialized mask for perf (causal handled inside kernels)\n",
        "        def fn_v1():\n",
        "            return flashattn_v1_triton(Q, K, V, mask=None, causal=causal, cfg=cfg_v1)\n",
        "\n",
        "        def fn_v2():\n",
        "            return flashattn_v2_splitk_triton(Q, K, V, mask=None, causal=causal, cfg=cfg_v2)\n",
        "\n",
        "        ms_v1 = cuda_time_ms(fn_v1)\n",
        "        ms_v2 = cuda_time_ms(fn_v2)\n",
        "        speedup = (ms_v1 / ms_v2) if ms_v2 > 0 else float(\"inf\")\n",
        "        print(f\"| {N} | {ms_v1:7.4f} | {ms_v2:7.4f} | {speedup:14.2f}x |\")\n",
        "\n",
        "\n",
        "def main():\n",
        "    if not torch.cuda.is_available():\n",
        "        raise RuntimeError(\"CUDA required.\")\n",
        "\n",
        "    # T4-friendly starters\n",
        "    cfg_v1 = FlashV1Cfg(BLOCK_M=64, BLOCK_N=64, BLOCK_D=64, num_warps=4, num_stages=1)\n",
        "    cfg_v2 = FlashV2Cfg(BLOCK_M=64, BLOCK_N=64, BLOCK_D=64, num_splits=4, num_warps=4, num_stages=1)\n",
        "\n",
        "    # correctness on small N first\n",
        "    check_correctness(N=256, D=64, causal=True, use_mask=False, cfg_v1=cfg_v1, cfg_v2=cfg_v2)\n",
        "\n",
        "    # perf\n",
        "    compare_perf(N_list=[256, 512, 1024, 2048], D=64, causal=True, cfg_v1=cfg_v1, cfg_v2=cfg_v2)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gilp3I4Pppu",
        "outputId": "5d739f09-b07c-46cc-c6ca-fc93883ed619"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Correctness] N=256 D=64 dtype=torch.float16 use_mask=False causal=True\n",
            "  v1 max_abs=2.441e-04 mean_abs=4.479e-08\n",
            "  v2 max_abs=nan mean_abs=nan\n",
            "| N | v1 ms | v2 ms | v2/v1 speedup |\n",
            "|---|------:|------:|--------------:|\n",
            "| 256 |  0.2352 |  0.3407 |           0.69x |\n",
            "| 512 |  0.4575 |  0.9071 |           0.50x |\n",
            "| 1024 |  0.8932 |  3.6534 |           0.24x |\n",
            "| 2048 |  2.3417 | 12.0738 |           0.19x |\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}